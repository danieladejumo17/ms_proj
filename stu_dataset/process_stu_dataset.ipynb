{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc617e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/Dev/ms_proj/stu_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Dev/ms_proj/cosmos-reason1/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# %cd ../stu_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7347974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# Normalize intensities\n",
    "def normalize_intensities(intensities):\n",
    "    return np.clip(intensities / 255, 0, 1)\n",
    "\n",
    "\n",
    "# Filter points that are inside a given polygon\n",
    "def filter_points_in_polygon(image_points, polygon, corresponding_3d_points):\n",
    "    path = Path(polygon)\n",
    "    inside = path.contains_points(image_points)\n",
    "    return image_points[inside], corresponding_3d_points[inside], inside\n",
    "\n",
    "\n",
    "# Save colored point cloud as a PCD file\n",
    "def save_colored_pcd(points, colors, output_pcd_file):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    o3d.io.write_point_cloud(output_pcd_file, pcd)\n",
    "    print(f\"Saved colored PCD at: {output_pcd_file}\")\n",
    "\n",
    "\n",
    "def load_point_cloud(scan_path):\n",
    "    scan = np.fromfile(scan_path, dtype=np.float32)\n",
    "    scan = scan.reshape(\n",
    "        (-1, 4)\n",
    "    )  # The point cloud data is stored in a Nx4 format (x, y, z, intensity)\n",
    "    points = scan[:, :3]  # Extracting the (x, y, z) coordinates\n",
    "    intensities = scan[:, 3:]  # Extracting the (x, y, z) coordinates\n",
    "    return (points, intensities)\n",
    "\n",
    "\n",
    "def load_labels(label_path):\n",
    "    labels = np.fromfile(label_path, dtype=np.uint32).astype(np.int32)\n",
    "    semantic_label = labels & 0xFFFF\n",
    "    instance_label = labels >> 16\n",
    "    return semantic_label, instance_label\n",
    "\n",
    "\n",
    "def project_points_pinhole(points, camera_matrix, dist_coeffs):\n",
    "    if points.size == 0:\n",
    "        return (np.array([]), np.array([]))\n",
    "    rvec = np.zeros((3, 1))\n",
    "    tvec = np.zeros((3, 1))\n",
    "    image_points, _ = cv2.projectPoints(\n",
    "        points.reshape(-1, 1, 3), rvec, tvec, camera_matrix, dist_coeffs\n",
    "    )\n",
    "    image_points = image_points.reshape(-1, 2)\n",
    "    return image_points\n",
    "\n",
    "\n",
    "def transform_points(points, T):\n",
    "    points_hom = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    points_transformed = (T @ points_hom.T).T[:, :3]\n",
    "    return points_transformed\n",
    "\n",
    "\n",
    "def get_image_labels(\n",
    "    base_path,\n",
    "    idx,\n",
    "    image_width,\n",
    "    image_height,\n",
    "    camera_matrix,\n",
    "    dist_coeffs,\n",
    "    translation,\n",
    "    yaw,\n",
    "    pitch,\n",
    "    roll,\n",
    "):\n",
    "    label_file = base_path / f\"labels/{idx:06d}.label\"\n",
    "    point_file = base_path / f\"velodyne/{idx:06d}.bin\"\n",
    "    # \n",
    "    label_file = Path(label_file)\n",
    "    labels, _ = load_labels(label_file)\n",
    "    points, _ = load_point_cloud(point_file)\n",
    "    # \n",
    "    labels[(labels != 2) & (labels != 0)] = 1\n",
    "    # \n",
    "    # Construct the transformation matrix\n",
    "    r = R.from_euler(\"ZYX\", [yaw, pitch, roll])\n",
    "    rotation_matrix = r.as_matrix()\n",
    "    transformation_inv = np.eye(4)\n",
    "    transformation_inv[:3, :3] = rotation_matrix.T\n",
    "    transformation_inv[:3, 3] = -np.dot(rotation_matrix.T, translation)\n",
    "    # \n",
    "    # Transform points into the camera frame\n",
    "    points_transformed = transform_points(points, transformation_inv)\n",
    "    # \n",
    "    # Use only points in front of the camera (z > 0)\n",
    "    valid_indices = points_transformed[:, 2] > 0\n",
    "    points_camera_valid = points_transformed[valid_indices]\n",
    "    valid_labels = labels[valid_indices]\n",
    "    # \n",
    "    # Project to image plane\n",
    "    image_points = project_points_pinhole(\n",
    "        points_camera_valid, camera_matrix, dist_coeffs\n",
    "    )\n",
    "    # \n",
    "    # Convert projected points to integer coordinates\n",
    "    pts_int = image_points.astype(int)\n",
    "    # \n",
    "    # Filter points that lie within image bounds\n",
    "    inside_mask = (\n",
    "        (pts_int[:, 0] >= 0)\n",
    "        & (pts_int[:, 0] < image_width)\n",
    "        & (pts_int[:, 1] >= 0)\n",
    "        & (pts_int[:, 1] < image_height)\n",
    "    )\n",
    "    pts_in = pts_int[inside_mask]\n",
    "    valid_labels = valid_labels[inside_mask]\n",
    "    # \n",
    "    # return pts_in, valid_labels, image\n",
    "    return np.hstack((pts_in, valid_labels[:, None]))\n",
    "\n",
    "\n",
    "# class STUDataset(Dataset):\n",
    "class STUDataset():\n",
    "    def __init__(self, base_path, offset=0, transform=None, single_scene=False):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.transform = transform\n",
    "        self.offset = offset\n",
    "        if single_scene: # base_path/velodyne/*.bin\n",
    "            self.data = sorted(list(self.base_path.glob(\"velodyne/*.bin\")))\n",
    "        else: # base_path/101/velodyne/*.bin\n",
    "            self.data = sorted(list(self.base_path.glob(\"*/velodyne/*.bin\")))\n",
    "        # \n",
    "        self.image_width = 1920\n",
    "        self.image_height = 1208\n",
    "        self.camera_matrix = np.array(\n",
    "            [\n",
    "                [1827.48989, 0.0, 925.91346],\n",
    "                [0.0, 1835.88358, 642.07154],\n",
    "                [0.0, 0.0, 1.0],\n",
    "            ]\n",
    "        )\n",
    "        self.dist_coeffs = np.array([-0.260735, 0.046071, 0.001173, -0.000154, 0.0])\n",
    "        self.translation = np.array([0.7658, 0.0124, -0.3925])\n",
    "        self.yaw = -1.5599\n",
    "        self.pitch = 0.0188\n",
    "        self.roll = -1.5563\n",
    "    # \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    # \n",
    "    def __getitem__(self, idx):\n",
    "        # 2 - anomaly\n",
    "        # 0 - ignore\n",
    "        # 1 - inlier\n",
    "        base_path = self.data[idx].parent.parent\n",
    "        idx = int(self.data[idx].stem)\n",
    "        image_file = str(base_path / \"port_a_cam_0\" / (f\"{idx:06d}\" + \".png\"))\n",
    "        image = Image.open(image_file)  # BGR format by default\n",
    "        # \n",
    "        # Apply optional transformation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # \n",
    "        label = get_image_labels(\n",
    "            base_path,\n",
    "            idx,\n",
    "            image.size[0],\n",
    "            image.size[1],\n",
    "            self.camera_matrix,\n",
    "            self.dist_coeffs,\n",
    "            self.translation,\n",
    "            self.yaw,\n",
    "            self.pitch,\n",
    "            self.roll,\n",
    "        )\n",
    "        # \n",
    "        return image, label, image_file\n",
    "\n",
    "    def get_predictions_targets(self, uncertainty, target):\n",
    "        coords = target.squeeze(0)\n",
    "\n",
    "        # Separate indices\n",
    "        x_indices = coords[:, 0]  # Width (columns)\n",
    "        y_indices = coords[:, 1]  # Height (rows)\n",
    "        labels_1 = coords[\n",
    "            :, 2\n",
    "        ]  # Label (0 = negative, 1 = positive, 2 = ignored)\n",
    "\n",
    "        x_indices = torch.clamp(x_indices, 0, self.image_width - 1)\n",
    "        y_indices = torch.clamp(y_indices, 0, self.image_height - 1)\n",
    "\n",
    "        # Sample pixel values\n",
    "        sampled_values = uncertainty[y_indices, x_indices]\n",
    "\n",
    "        # Separate into categories\n",
    "        uncertainty = sampled_values[labels_1 != 0]  # Pixels with label 0\n",
    "        labels = labels_1[labels_1 != 0] - 1\n",
    "        return uncertainty, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fa83e",
   "metadata": {},
   "source": [
    "# STU Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ds_chunk(chunk, anomaly_label=2):\n",
    "    # chunk: [(image, label, image_file_path), ...]\n",
    "    # return ([images], single_label)\n",
    "    # extract images and labels    \n",
    "    images = [item[0] for item in chunk]\n",
    "    labels = [item[1] for item in chunk]\n",
    "    # \n",
    "    # process labels\n",
    "    # labels: [[[x1, y1, label1], [x2, y2, label2], ...], ...]\n",
    "    # extract a single lable for each [x1, y1, label1], [x2, y2, label2], ...] in the labels list\n",
    "    # flaten labels on second axis\n",
    "    # \n",
    "    processed_labels = [np.any(label[:, 2] == anomaly_label) for label in labels]\n",
    "    # processed_labels = [\n",
    "    # for label in labels:\n",
    "        # processed_labels.append(np.any(label[:, 2] == anomaly_label))\n",
    "    # processed_labels = np.any(labels[:, :, 2] == anomaly_label, axis=1)\n",
    "    # \n",
    "    return images, processed_labels # images: [PIL Image], processed_labels: [np.boolean]\n",
    "\n",
    "def video_from_images(image_list, output_path, fps=10):\n",
    "    if len(image_list) == 0:\n",
    "        print(\"No images to create video.\")\n",
    "        return\n",
    "    # \n",
    "    # Get dimensions from the first image\n",
    "    first_image = image_list[0]\n",
    "    width, height = first_image.size\n",
    "    # \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can use other codecs as well\n",
    "    video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    # \n",
    "    for img in image_list:\n",
    "        # Convert PIL Image to OpenCV format\n",
    "        img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "        video_writer.write(img_cv)\n",
    "    # \n",
    "    video_writer.release()\n",
    "    # print(f\"Video saved at {output_path}\")\n",
    "\n",
    "def iter_ds(ds, window_size=50, step_size=20, video_output_path=\"output_video.mp4\", fps=10):\n",
    "    if window_size > len(ds):\n",
    "        images, labels = process_ds_chunk(ds)\n",
    "        # create a video from images\n",
    "        video_from_images(images, video_output_path, fps=fps)\n",
    "        yield video_output_path, np.any(labels), images\n",
    "        return\n",
    "    # \n",
    "    ret, ret_labels = process_ds_chunk([ds[i] for i in range(window_size - step_size)]) # get the first window_size - step_size frames\n",
    "    first_sample = True\n",
    "    for i in range(window_size - step_size, len(ds), step_size):\n",
    "        # get the next step_size frames and labels\n",
    "        ext = [ds[i + x] for x in range(step_size) if (i + x) < len(ds)]\n",
    "        images, labels = process_ds_chunk(ext)\n",
    "        #   \n",
    "        # update ret and ret_labels\n",
    "        ret.extend(images)\n",
    "        ret_labels.extend(labels)\n",
    "        # \n",
    "        # create a video from images\n",
    "        out_path = Path(video_output_path)\n",
    "        file_stem = f\"{out_path.stem}_{i}\"\n",
    "        file_suffix = out_path.suffix\n",
    "        filename = file_stem + file_suffix\n",
    "        out_path_video = out_path.parent / filename\n",
    "        print(\"Wrinting video to\", out_path_video)\n",
    "        \n",
    "        video_from_images(ret, f\"{out_path_video}\", fps=fps) # FIXME\n",
    "        # video_from_images(ret, video_output_path, fps=fps)\n",
    "        if first_sample:\n",
    "            first_sample = False\n",
    "            yield video_output_path, np.any(ret_labels), ret\n",
    "        else:    \n",
    "            yield video_output_path, np.any(ret_labels), images\n",
    "        # \n",
    "        # shift the window\n",
    "        ret = ret[step_size:]  # slide the window by step_size\n",
    "        ret_labels = ret_labels[step_size:]\n",
    "\n",
    "        # if first yield return ret, otherwise return ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = STUDataset(\"val/125/\", single_scene=True)\n",
    "ds_iter = iter_ds(ds, window_size=50, step_size=20, video_output_path=\"output_videos/output_video.mp4\", fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed7f3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('output_videos/output_video_1.mp4')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "out_path = Path(\"output_videos/output_video.mp4\")\n",
    "file_stem = f\"{out_path.stem}_{1}\"\n",
    "file_suffix = out_path.suffix\n",
    "filename = file_stem + file_suffix\n",
    "out_path_video = out_path.parent / filename\n",
    "out_path_video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc88f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3b05d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13026/1656482010.py:110: RuntimeWarning: invalid value encountered in cast\n",
      "  pts_int = image_points.astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('output_video.mp4', np.True_, [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F849C6EBC40>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F849C686530>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F849C6864A0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BA90>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BAC0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BE20>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BD00>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BCA0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BC40>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BBE0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BB80>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BB20>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BA30>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574B9D0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574B970>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574B910>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574B730>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574B700>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BE80>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BE50>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BEB0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BEE0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F829574BF40>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0070>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0040>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF00A0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0100>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0160>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF01C0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0220>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0370>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0340>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF03A0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF03D0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0430>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0490>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF04F0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0550>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF05B0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0610>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0670>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF06D0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0730>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0790>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF07F0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0850>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF08B0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0910>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF0970>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1920x1208 at 0x7F8294DF09D0>])\n"
     ]
    }
   ],
   "source": [
    "for x in ds_iter:\n",
    "    # if not x[1]:\n",
    "        # break\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "141e7986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cp output_video.mp4 /mnt/c/Users/adeju/Downloads/output_video.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9d717",
   "metadata": {},
   "source": [
    "## Pass Model Through Cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daa1cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import qwen_vl_utils\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646cd7e",
   "metadata": {},
   "source": [
    "#### Load Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54fee970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f167691a0b314855b82dd2ed8c96e094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model_name = \"nvidia/Cosmos-Reason1-7B\"\n",
    "model = transformers.Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_name, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "processor: transformers.Qwen2_5_VLProcessor = (\n",
    "    transformers.AutoProcessor.from_pretrained(model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff49ce0",
   "metadata": {},
   "source": [
    "#### Create Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7cbcf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"output_video.mp4\"\n",
    "user_prompt = (\n",
    "            \"You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\\n\\n\"\n",
    "            \"<think>\\n\"\n",
    "            \"Focus on:\\n\"\n",
    "            \"- Obstacles, pedestrians, or vehicles violating rules\\n\"\n",
    "            \"- Roadwork, blocked lanes, poor visibility, or hazards\\n\"\n",
    "            \"- Reflections, shadows, or false visual cues confusing perception\\n\"\n",
    "            \"</think>\\n\\n\"\n",
    "            \"<answer>\\n\"\n",
    "            \"Is there any external anomaly in this video? Reply with exactly one of the following:\\n\"\n",
    "            \"Classification: Anomaly — if any obstacle, obstruction, or unsafe condition is visible.\\n\"\n",
    "            \"Classification: Normal — if no anomaly or obstruction is visible.\\n\"\n",
    "            \"</answer>\"\n",
    "        ),\n",
    "# TODO: tuple?????\n",
    "\n",
    "\n",
    "# Conversation template\n",
    "conversation = [\n",
    "    { \n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"video\",\n",
    "                \"video\": video_path,\n",
    "                \"fps\": 4,\n",
    "                \"total_pixels\": 4096 * 30**2,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\", \n",
    "                \"text\": user_prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cada19",
   "metadata": {},
   "source": [
    "#### Process Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e6da6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.48 s, sys: 1.24 s, total: 2.72 s\n",
      "Wall time: 396 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Process inputs\n",
    "text = processor.apply_chat_template(\n",
    "    conversation, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "image_inputs, video_inputs = qwen_vl_utils.process_vision_info(conversation)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8230f69",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Qwen2_5_VLForConditionalGeneration' object has no attribute 'get_vision_tower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     vision_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vision_tower\u001b[49m()(video_inputs)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(vision_outputs\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Dev/ms_proj/cosmos-reason1/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1962\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1962\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1964\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Qwen2_5_VLForConditionalGeneration' object has no attribute 'get_vision_tower'"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    vision_outputs = model.get_vision_tower()(video_inputs)\n",
    "print(vision_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "788f83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_a = \"\"\"You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
    "\n",
    "<think>\n",
    "- Obstacles, pedestrians, or vehicles violating rules\n",
    "- Roadwork, blocked lanes, poor visibility, or hazards\n",
    "- Reflections, shadows, or false visual cues confusing perception\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "Is there any external anomaly in this video? Reply with exactly one word of the following:\n",
    "Classification: Anomaly — if any obstacle, obstruction, or unsafe condition is visible.\n",
    "Classification: Normal — if no anomaly or obstruction is visible.\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "prompt_b = \"\"\"You are an autonomous driving safety and perception expert analyzing this video for potential EXTERNAL ANOMALIES that could affect the safe and predictable operation of an autonomous vehicle.\n",
    "\n",
    "<think>\n",
    "\"CRITICAL ANOMALIES:\\n\"\n",
    "- Unexpected obstacles on or near the roadway (debris, animals, fallen objects)\n",
    "- Pedestrians or cyclists entering or approaching the vehicle’s path\n",
    "- Vehicles violating traffic rules (red-light running, wrong-way driving, illegal turns)\n",
    "- Close calls or near-collision situations involving any road user\n",
    "- Road work zones, blocked lanes, or temporary cones\n",
    "- Emergency vehicles or flashing lights impacting traffic flow\n",
    "- Missing, obscured, or malfunctioning traffic signals/signs\n",
    "- Road surface hazards (potholes, water puddles, ice, uneven terrain)\n",
    "- Stopped or stalled vehicles obstructing lanes\n",
    "- Unusual or unpredictable movement of surrounding objects or road users\n",
    "\"CONTEXT MISINTERPRETATION ANOMALIES:\"\n",
    "- Situations where the vehicle might misclassify or misinterpret visual cues\n",
    "    (e.g., a person wearing clothing with a STOP sign print mistaken for a real traffic sign)\n",
    "- False positives due to reflections, shadows, or advertisements resembling real road objects\n",
    "- Unclear or deceptive visual context (e.g., temporary paint, digital displays, mirrored surfaces)\n",
    "- Any environment where perception sensors might interpret context incorrectly and trigger false actions\n",
    "\"OTHER SAFETY CONCERNS:\"\n",
    "- Speeding or aggressive driving by surrounding vehicles\n",
    "- Unsafe lane changes, tailgating, or sudden stops\n",
    "- Faded or missing lane markings\n",
    "- Poor visibility (fog, glare, heavy rain, low light)\n",
    "- Overcrowded intersections or congested roadways\n",
    "- Objects falling from moving vehicles (cargo, equipment)\n",
    "- Environmental interference (smoke, dust, reflections)\n",
    "- Any condition likely to reduce sensor or perception reliability\n",
    "Analyze the video carefully and identify all external anomalies and context-related perception issues that could cause unsafe or unpredictable autonomous vehicle behavior.Focus especially on how environmental context could lead to false detection or unsafe reaction.\n",
    "</think>\n",
    "<answer>\n",
    "Is there any external anomaly  in this video? \n",
    "</answer>\"\"\"\n",
    "\n",
    "prompt_c = \"\"\"I am the fault monitor for a vision-based autonomous vehicle. My job is to analyze the vehicle’s observations and identify anything that could cause the vehicle to take actions that are unsafe, unpredictable or violate traffic rules. For each object that the vehicle observes, I will reason about whether the object constitutes a normal observation or an anomaly. Normal observations do not detrimentally affect the vehicle’s performance, whereas anomalies might. Finally, I will classify whether the overall scene is normal or abnormal.\n",
    "\n",
    "<think>\n",
    "1. Is this common to see while driving?\n",
    "2. Can this influence the vehicle’s behavior?\n",
    "3. Can the vehicle drive safely in its presence?\n",
    "4. Can this cause the vehicle to make unpredictable or unsafe maneuvers?\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "Give your classification as 'Classification: Normal' or 'Classification: Anomaly'\n",
    "</answer>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a91f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in the prompt: 122\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text and count the number of tokens\n",
    "tokenized_text = processor.tokenizer(user_prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "num_tokens = tokenized_text.input_ids.size(1)\n",
    "print(f\"Number of tokens in the prompt: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec83bc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   40,  1079,   279, 14527,  8718,   369,   264, 11129,  5980, 38193,\n",
       "          7310,    13,  3017,  2618,   374,   311, 23643,   279,  7310,   748,\n",
       "         23722,   323, 10542,  4113,   429,  1410,  5240,   279,  7310,   311,\n",
       "          1896,  6168,   429,   525, 19860,    11, 49135,   476, 40487,  9442,\n",
       "          5601,    13,  1752,  1817,  1633,   429,   279,  7310, 80199,    11,\n",
       "           358,   686,  2874,   911,  3425,   279,  1633, 41575,   264,  4622,\n",
       "         21930,   476,   458, 62948,    13, 18437, 23722,   653,   537, 48908,\n",
       "           745,  7802,   279,  7310,   748,  5068,    11, 19853, 74459,  2578,\n",
       "            13, 17375,    11,   358,   686, 48129,  3425,   279,  8084,  6109,\n",
       "           374,  4622,   476, 34563,   382, 13708,   766,   397,    16,    13,\n",
       "          2160,   419,  4185,   311,  1490,  1393,  9842,  5267,    17,    13,\n",
       "          2980,   419, 10173,   279,  7310,   748,  7709,  5267,    18,    13,\n",
       "          2980,   279,  7310,  6541, 21000,   304,  1181,  9362,  5267,    19,\n",
       "            13,  2980,   419,  5240,   279,  7310,   311,  1281, 49135,   476,\n",
       "         19860, 95791,  5267,   522, 26865,  1339,    27,  9217,   397, 35127,\n",
       "           697, 23850,   438,   364, 85040,    25, 18437,     6,   476,   364,\n",
       "         85040,    25,  1527, 83092,  1248,   522,  9217,    29]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5a39f",
   "metadata": {},
   "source": [
    "#### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67eb83cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.37 s, sys: 4.09 s, total: 12.5 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run inference\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add2e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Normal\n"
     ]
    }
   ],
   "source": [
    "# print result\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :]\n",
    "    for in_ids, out_ids in zip(inputs.input_ids, generated_ids, strict=False)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False,\n",
    ")\n",
    "\n",
    "print(output_text[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f7bfd",
   "metadata": {},
   "source": [
    "#### Run for Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d26acce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_run():\n",
    "    text = processor.apply_chat_template(\n",
    "        conversation, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = qwen_vl_utils.process_vision_info(conversation)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=8)\n",
    "\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :]\n",
    "        for in_ids, out_ids in zip(inputs.input_ids, generated_ids, strict=False)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False,\n",
    "    )\n",
    "\n",
    "    return output_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b96d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = STUDataset(\"val/\")\n",
    "# ds_iter = iter_ds(ds, window_size=50, step_size=20, video_output_path=\"output_video.mp4\", fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3150640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import subprocess\n",
    "# from pathlib import Path\n",
    "# import sys\n",
    "\n",
    "# def move_contents_py(src: Path, dst: Path) -> None:\n",
    "#     \"\"\"Move every entry inside src into dst using shutil (preserves metadata).\"\"\"\n",
    "#     if not src.exists():\n",
    "#         raise FileNotFoundError(f\"source not found: {src}\")\n",
    "#     dst.mkdir(parents=True, exist_ok=True)\n",
    "#     for entry in src.iterdir():\n",
    "#         # skip special entries if any (not strictly necessary with Path.iterdir)\n",
    "#         target = dst / entry.name\n",
    "#         shutil.move(str(entry), str(target))\n",
    "\n",
    "# def sudo_move_glob(src: Path, dst: Path) -> None:\n",
    "#     \"\"\"\n",
    "#     Fallback using the shell to expand wildcards, run under sudo.\n",
    "#     This will prompt for the sudo password interactively (unless cached).\n",
    "#     \"\"\"\n",
    "#     # Use bash -lc so shell expansion works reliably and quoting is easier\n",
    "#     cmd = f\"sudo bash -lc 'mv \\\"{src}\\\"/* \\\"{dst}\\\"'\"\n",
    "#     print(\"Running fallback command:\", cmd)\n",
    "#     res = subprocess.run(cmd, shell=True)\n",
    "#     if res.returncode != 0:\n",
    "#         raise RuntimeError(f\"sudo mv failed with return code {res.returncode}\")\n",
    "\n",
    "# def safe_move_with_fallback(src: str, dst: str) -> None:\n",
    "#     src_p = Path(src)\n",
    "#     dst_p = Path(dst)\n",
    "#     try:\n",
    "#         move_contents_py(src_p, dst_p)\n",
    "#         print(f\"Moved contents from {src} -> {dst} using Python shutil.\")\n",
    "#     except PermissionError as e:\n",
    "#         print(f\"PermissionError while moving with Python: {e}. Trying sudo fallback...\")\n",
    "#         sudo_move_glob(src_p, dst_p)\n",
    "#     except Exception as e:\n",
    "#         # If other errors happen (e.g., file in use), either raise or fallback\n",
    "#         print(f\"Error while moving with Python: {e}. Trying sudo fallback...\")\n",
    "#         sudo_move_glob(src_p, dst_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e392ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root = Path(\"val/\")\n",
    "# eval_folder = Path(\"cosmos_val/101/\")\n",
    "\n",
    "# # iterate through the folders in data_root\n",
    "# for folder in sorted(data_root.iterdir()):\n",
    "#     if folder.is_dir():\n",
    "#         print(f\"Processing folder: {folder.name}\")\n",
    "\n",
    "#         # move all the contents of folder to eval_folder - use eval_folder defined above. Use command line mv\n",
    "#         # src1 = \"val/126\"\n",
    "#         # dst1 = \"cosmos_val/101\"\n",
    "\n",
    "#         # src2 = \"cosmos_val/101\"\n",
    "#         # dst2 = \"val/126\"\n",
    "\n",
    "#         # First move: sudo mv val/126/* cosmos_val/101/\n",
    "#         safe_move_with_fallback(data_root/folder.name , eval_folder)\n",
    "\n",
    "#         # Second move: sudo mv cosmos_val/101/* val/126/\n",
    "#         # safe_move_with_fallback(eval_folder, data_root/folder.name)\n",
    "\n",
    "#     break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46c5a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# import seaborn as sns\n",
    "\n",
    "def compute_metrics(predictions, actuals):\n",
    "    # Accuracy calculation\n",
    "    correct = sum(p == a for p, a in zip(predictions, actuals))\n",
    "    accuracy = correct / len(actuals) if actuals else 0\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Computer precision, recall, F1-score\n",
    "    precision = precision_score(actuals, predictions)\n",
    "    recall = recall_score(actuals, predictions)\n",
    "    f1 = f1_score(actuals, predictions)\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F1-score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    # True Positives, False Positives, True Negatives, False Negatives\n",
    "    tp = sum((p == 1) and (a == 1) for p, a in zip(predictions, actuals))\n",
    "    fp = sum((p == 1) and (a == 0) for p, a in zip(predictions, actuals))\n",
    "    tn = sum((p == 0) and (a == 0) for p, a in zip(predictions, actuals))\n",
    "    fn = sum((p == 0) and (a == 1) for p, a in zip(predictions, actuals))\n",
    "    print(\"=\"*30)\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "\n",
    "def plot_confusion_matrix(predictions, actuals):\n",
    "    # cm = confusion_matrix(actuals, predictions)\n",
    "    # plt.figure(figsize=(6, 4))\n",
    "    # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n",
    "    # plt.xlabel('Predicted Label')\n",
    "    # plt.ylabel('True Label')\n",
    "    # plt.title('Confusion Matrix')\n",
    "    # plt.show()\n",
    "\n",
    "    \n",
    "    tp = sum((p == 1) and (a == 1) for p, a in zip(predictions, actuals))\n",
    "    fp = sum((p == 1) and (a == 0) for p, a in zip(predictions, actuals))\n",
    "    tn = sum((p == 0) and (a == 0) for p, a in zip(predictions, actuals))\n",
    "    fn = sum((p == 0) and (a == 1) for p, a in zip(predictions, actuals))\n",
    "    cm = np.array([[tn, fp], [fn, tp]])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Anomaly\"])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "656bf660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/Dev/ms_proj/stu_dataset\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92ba58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5995/1656482010.py:110: RuntimeWarning: invalid value encountered in cast\n",
      "  pts_int = image_points.astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tActual: True, Predicted: True ---- [1/11.25]\n",
      "\tActual: True, Predicted: True ---- [2/11.25]\n",
      "\tActual: True, Predicted: False ---- [3/11.25]\n",
      "\tActual: True, Predicted: True ---- [4/11.25]\n",
      "\tActual: True, Predicted: False ---- [5/11.25]\n",
      "\tActual: True, Predicted: False ---- [6/11.25]\n",
      "\tActual: True, Predicted: False ---- [7/11.25]\n",
      "\tActual: True, Predicted: False ---- [8/11.25]\n",
      "\tActual: False, Predicted: False ---- [9/11.25]\n",
      "\tActual: False, Predicted: False ---- [10/11.25]\n",
      "\tActual: False, Predicted: False ---- [11/11.25]\n",
      "\tActual: False, Predicted: False ---- [12/11.25]\n",
      "Processed video saved at val_out/125_out.mp4\n",
      "==============================\n",
      "Accuracy: 58.33%\n",
      "==============================\n",
      "Precision: 100.00%\n",
      "Recall: 37.50%\n",
      "F1-score: 54.55%\n",
      "==============================\n",
      "True Positives: 3\n",
      "False Positives: 0\n",
      "True Negatives: 4\n",
      "False Negatives: 5\n",
      "Overall Metrics:\n",
      "==============================\n",
      "Accuracy: 58.33%\n",
      "==============================\n",
      "Precision: 100.00%\n",
      "Recall: 37.50%\n",
      "F1-score: 54.55%\n",
      "==============================\n",
      "True Positives: 3\n",
      "False Positives: 0\n",
      "True Negatives: 4\n",
      "False Negatives: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAHHCAYAAAAbLeozAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPwRJREFUeJzt3Xt8THf+x/H3JGQiclN1C5G4VCSuVbZL6tamtEWFVdeuhOr9onVZtV3XbBttXYq2ats0QSnaYpdeqWtJtygtGqm4FKXVUolQEcn5/WEzv44kzJjJjMPr6XEea75zzvf7mdmUj+/n+z3HYhiGIQAAgDLm4+0AAADA9YGkAwAAeARJBwAA8AiSDgAA4BEkHQAAwCNIOgAAgEeQdAAAAI8g6QAAAB5B0gEAADyCpAO4xu3Zs0edOnVSSEiILBaLli1b5tb+Dxw4IIvForS0NLf2a2YdOnRQhw4dvB0GcNUh6QA8YO/evXr44YdVt25d+fv7Kzg4WLGxsZo+fbp+//33Mh07ISFBO3bs0PPPP6958+apZcuWZTqeJyUmJspisSg4OLjE73HPnj2yWCyyWCyaPHmy0/0fOXJE48eP1/bt290QLYBy3g4AuNZ9+OGHuu+++2S1WjVw4EA1btxY586d0xdffKGRI0dq165d+te//lUmY//+++9KT0/Xc889pyeeeKJMxoiIiNDvv/+u8uXLl0n/l1OuXDmdOXNGy5cvV+/eve3emz9/vvz9/XX27Nkr6vvIkSOaMGGCIiMj1bx5c4ev++yzz65oPOBaR9IBlKH9+/erb9++ioiI0OrVq1WjRg3be48//riysrL04Ycfltn4v/zyiyQpNDS0zMawWCzy9/cvs/4vx2q1KjY2Vu+++26xpGPBggXq0qWLPvjgA4/EcubMGQUEBMjPz88j4wFmQ3kFKEMvvfSScnNzlZKSYpdwFKlfv76GDh1qe33+/HklJSWpXr16slqtioyM1N///nfl5eXZXRcZGamuXbvqiy++0J/+9Cf5+/urbt26mjt3ru2c8ePHKyIiQpI0cuRIWSwWRUZGSrpQlij6/R+NHz9eFovFrm3lypW67bbbFBoaqsDAQEVFRenvf/+77f3S1nSsXr1abdu2VcWKFRUaGqru3bsrIyOjxPGysrKUmJio0NBQhYSEaNCgQTpz5kzpX+xF+vfvr48//lgnT560tW3evFl79uxR//79i51/4sQJjRgxQk2aNFFgYKCCg4N1991365tvvrGds3btWrVq1UqSNGjQIFuZpuhzdujQQY0bN9bWrVvVrl07BQQE2L6Xi9d0JCQkyN/fv9jn79y5sypVqqQjR444/FkBMyPpAMrQ8uXLVbduXbVp08ah84cMGaKxY8eqRYsWmjZtmtq3b6/k5GT17du32LlZWVnq1auX7rzzTk2ZMkWVKlVSYmKidu3aJUnq2bOnpk2bJknq16+f5s2bp1deecWp+Hft2qWuXbsqLy9PEydO1JQpU3Tvvfdq48aNl7xu1apV6ty5s44dO6bx48dr2LBh2rRpk2JjY3XgwIFi5/fu3VunTp1ScnKyevfurbS0NE2YMMHhOHv27CmLxaIlS5bY2hYsWKCGDRuqRYsWxc7ft2+fli1bpq5du2rq1KkaOXKkduzYofbt29sSgOjoaE2cOFGS9NBDD2nevHmaN2+e2rVrZ+vn+PHjuvvuu9W8eXO98sor6tixY4nxTZ8+XVWqVFFCQoIKCgokSbNnz9Znn32mmTNnKiwszOHPCpiaAaBMZGdnG5KM7t27O3T+9u3bDUnGkCFD7NpHjBhhSDJWr15ta4uIiDAkGevXr7e1HTt2zLBarcbw4cNtbfv37zckGS+//LJdnwkJCUZERESxGMaNG2f88Y+FadOmGZKMX375pdS4i8ZITU21tTVv3tyoWrWqcfz4cVvbN998Y/j4+BgDBw4sNt7gwYPt+uzRo4dRuXLlUsf84+eoWLGiYRiG0atXL+OOO+4wDMMwCgoKjOrVqxsTJkwo8Ts4e/asUVBQUOxzWK1WY+LEiba2zZs3F/tsRdq3b29IMt54440S32vfvr1d26effmpIMv75z38a+/btMwIDA434+PjLfkbgWsJMB1BGcnJyJElBQUEOnf/RRx9JkoYNG2bXPnz4cEkqtvYjJiZGbdu2tb2uUqWKoqKitG/fviuO+WJFa0H+/e9/q7Cw0KFrjh49qu3btysxMVE33HCDrb1p06a68847bZ/zjx555BG7123bttXx48dt36Ej+vfvr7Vr1+qnn37S6tWr9dNPP5VYWpEurAPx8bnwx19BQYGOHz9uKx19/fXXDo9ptVo1aNAgh87t1KmTHn74YU2cOFE9e/aUv7+/Zs+e7fBYwLWApAMoI8HBwZKkU6dOOXT+Dz/8IB8fH9WvX9+uvXr16goNDdUPP/xg1167du1ifVSqVEm//fbbFUZcXJ8+fRQbG6shQ4aoWrVq6tu3rxYvXnzJBKQozqioqGLvRUdH69dff9Xp06ft2i/+LJUqVZIkpz7LPffco6CgIC1atEjz589Xq1atin2XRQoLCzVt2jTddNNNslqtuvHGG1WlShV9++23ys7OdnjMmjVrOrVodPLkybrhhhu0fft2zZgxQ1WrVnX4WuBaQNIBlJHg4GCFhYVp586dTl138ULO0vj6+pbYbhjGFY9RtN6gSIUKFbR+/XqtWrVKf/3rX/Xtt9+qT58+uvPOO4ud6wpXPksRq9Wqnj17as6cOVq6dGmpsxyS9MILL2jYsGFq166d3nnnHX366adauXKlGjVq5PCMjnTh+3HGtm3bdOzYMUnSjh07nLoWuBaQdABlqGvXrtq7d6/S09Mve25ERIQKCwu1Z88eu/aff/5ZJ0+etO1EcYdKlSrZ7fQocvFsiiT5+Pjojjvu0NSpU/Xdd9/p+eef1+rVq7VmzZoS+y6KMzMzs9h7u3fv1o033qiKFSu69gFK0b9/f23btk2nTp0qcfFtkffff18dO3ZUSkqK+vbtq06dOikuLq7Yd+JoAuiI06dPa9CgQYqJidFDDz2kl156SZs3b3Zb/4AZkHQAZehvf/ubKlasqCFDhujnn38u9v7evXs1ffp0SRfKA5KK7TCZOnWqJKlLly5ui6tevXrKzs7Wt99+a2s7evSoli5danfeiRMnil1bdJOsi7fxFqlRo4aaN2+uOXPm2P0lvnPnTn322We2z1kWOnbsqKSkJL366quqXr16qef5+voWm0V577339OOPP9q1FSVHJSVozho1apQOHjyoOXPmaOrUqYqMjFRCQkKp3yNwLeLmYEAZqlevnhYsWKA+ffooOjra7o6kmzZt0nvvvafExERJUrNmzZSQkKB//etfOnnypNq3b6+vvvpKc+bMUXx8fKnbMa9E3759NWrUKPXo0UNPPfWUzpw5o1mzZqlBgwZ2CyknTpyo9evXq0uXLoqIiNCxY8f0+uuvq1atWrrttttK7f/ll1/W3XffrdatW+uBBx7Q77//rpkzZyokJETjx4932+e4mI+Pj/7xj39c9ryuXbtq4sSJGjRokNq0aaMdO3Zo/vz5qlu3rt159erVU2hoqN544w0FBQWpYsWKuvXWW1WnTh2n4lq9erVef/11jRs3zraFNzU1VR06dNCYMWP00ksvOdUfYFpe3j0DXBe+//5748EHHzQiIyMNPz8/IygoyIiNjTVmzpxpnD171nZefn6+MWHCBKNOnTpG+fLljfDwcGP06NF25xjGhS2zXbp0KTbOxVs1S9syaxiG8dlnnxmNGzc2/Pz8jKioKOOdd94ptmX2888/N7p3726EhYUZfn5+RlhYmNGvXz/j+++/LzbGxdtKV61aZcTGxhoVKlQwgoODjW7duhnfffed3TlF4128JTc1NdWQZOzfv7/U79Qw7LfMlqa0LbPDhw83atSoYVSoUMGIjY010tPTS9zq+u9//9uIiYkxypUrZ/c527dvbzRq1KjEMf/YT05OjhEREWG0aNHCyM/PtzvvmWeeMXx8fIz09PRLfgbgWmExDCdWagEAAFwh1nQAAACPIOkAAAAeQdIBAAA8gqQDAABcVtFTof94NGzY0Kk+2DILAAAc0qhRI61atcr2ulw559IIkg4AAOCQcuXKXfLGe5e93o2xwEWFhYU6cuSIgoKC3Hr7ZQCAZxiGoVOnTiksLMz2JOOycPbsWZ07d87lfgzDKPb3jdVqldVqLfH8PXv2KCwsTP7+/mrdurWSk5NLfPhkabhPx1Xk8OHDCg8P93YYAAAXHTp0SLVq1SqTvs+ePasKQZWl82dc7iswMFC5ubl2bePGjSvxzsEff/yxcnNzFRUVpaNHj2rChAn68ccftXPnTgUFBTk0HknHVSQ7O1uhoaGq3PcN+fg59/RKwCx2Tov3dghAmTmVk6P6dcJ18uRJhYSElMkYOTk5CgkJkTUmQfL1u/KOCs4p77s5OnTokIKDg23Nl5rp+KOiB1FOnTpVDzzwgENDUl65ihRNcfn4VZCPX4CXowHKxh//cAOuVR4pkZfzl8WFpMOwXCj/BAcHX9F/l6GhoWrQoIGysrIcvoYtswAAmJFFksXiwuHa8Lm5udq7d69q1Kjh8DUkHQAAmJHFx/XDCSNGjNC6det04MABbdq0ST169JCvr6/69evncB+UVwAAwGUdPnxY/fr10/Hjx1WlShXddttt+vLLL1WlShWH+yDpAADAjIrKJK5c74SFCxde+Vj/Q9IBAIAZXUGJpNj1HsaaDgAA4BHMdAAAYEYeLq+4A0kHAACm5GJ5xQvFDsorAADAI5jpAADAjCivAAAAj2D3CgAAQMmY6QAAwIworwAAAI8wYXmFpAMAADMy4UwHazoAAIBHMNMBAIAZUV4BAAAeYbG4mHRQXgEAANcoZjoAADAjH8uFw5XrPYykAwAAMzLhmg7KKwAAwCOY6QAAwIxMeJ8Okg4AAMyI8goAAEDJmOkAAMCMKK8AAACPMGF5haQDAAAzMuFMB2s6AACARzDTAQCAGVFeAQAAHkF5BQAAoGTMdAAAYEoulle8MO9A0gEAgBlRXgEAACgZMx0AAJiRxeLi7hXuSAoAABxhwi2zlFcAAIBHMNMBAIAZmXAhKUkHAABmZMLyCkkHAABmZMKZDtZ0AAAAj2CmAwAAM6K8AgAAPILyCgAAQMmY6QAAwIQsFossJpvpIOkAAMCEzJh0UF4BAAAewUwHAABmZPnf4cr1HkbSAQCACVFeAQAAKAUzHQAAmJAZZzpIOgAAMCGSDgAA4BFmTDpY0wEAADyCmQ4AAMyILbMAAMATKK8AAACUgpkOAABM6MKT7V2Z6XBfLI4i6QAAwIQscrG84oWsg/IKAADwCGY6AAAwITMuJCXpAADAjEy4ZZbyCgAA8AhmOgAAMCMXyysG5RUAAOAIV9d0uLbz5cqQdAAAYEJmTDpY0wEAAJw2adIkWSwWPf300w5fw0wHAABm5MXdK5s3b9bs2bPVtGlTp65jpgMAABMqKq+4clyJ3NxcDRgwQG+++aYqVark1LUkHQAAXMdycnLsjry8vEue//jjj6tLly6Ki4tzeiySDgAATMhdMx3h4eEKCQmxHcnJyaWOuXDhQn399deXPOdSWNMBAIAJuWv3yqFDhxQcHGxrt1qtJZ5/6NAhDR06VCtXrpS/v/8VjUnSAQDAdSw4ONgu6SjN1q1bdezYMbVo0cLWVlBQoPXr1+vVV19VXl6efH19L9kHSQcAACbk6ft03HHHHdqxY4dd26BBg9SwYUONGjXqsgmHRNIBAIA5eXjLbFBQkBo3bmzXVrFiRVWuXLlYe2lYSAoAADyCmQ4AAEzoargN+tq1a506n6QDAAATuhqSDmeRdAAAYEJmTDpY0wEAADyCmQ4AAMzIiw98u1IkHQAAmBDlFQAAgFKQdJShtWvXymKx6OTJk94OBZfwaKcoHZjVS2Pva+btUAC3enPxOjW9d6yqxz6tuMSXtXXXAW+HBDfy1qPtXWGapCMxMVEWi0WTJk2ya1+2bJlXvjhcG5pGVFL/tnWVcfikt0MB3GrJZ1v1j1eWatSQu7V23ig1vqmm/vLka/rlxClvhwY3scjFpMMLizpMk3RIkr+/v1588UX99ttvbuvz3LlzbusL5hJg9dUrg/6kZ+dvVfaZfG+HA7jV6wtWa2B8Gw24t7Ua1q2hqaP7KsDfT+/8J93boeE6ZqqkIy4uTtWrV1dycnKp53zwwQdq1KiRrFarIiMjNWXKFLv3IyMjlZSUpIEDByo4OFgPPfSQ0tLSFBoaqhUrVigqKkoBAQHq1auXzpw5ozlz5igyMlKVKlXSU089pYKCAltf8+bNU8uWLRUUFKTq1aurf//+OnbsWJl9frhXUt+btWbnT9q4m//PcG05l39e23cfUoc/RdnafHx81P5PUdq8Y78XI4M7UV4pY76+vnrhhRc0c+ZMHT58uNj7W7duVe/evdW3b1/t2LFD48eP15gxY5SWlmZ33uTJk9WsWTNt27ZNY8aMkSSdOXNGM2bM0MKFC/XJJ59o7dq16tGjhz766CN99NFHmjdvnmbPnq3333/f1k9+fr6SkpL0zTffaNmyZTpw4IASExPL8iuAm3RrWUuNwivppWU7Ln8yYDLHT+aqoKBQVW4IsmuvckOwjh3P8VJUcDuLGw4PM92W2R49eqh58+YaN26cUlJS7N6bOnWq7rjjDlsi0aBBA3333Xd6+eWX7ZKB22+/XcOHD7e93rBhg/Lz8zVr1izVq1dPktSrVy/NmzdPP//8swIDAxUTE6OOHTtqzZo16tOnjyRp8ODBtj7q1q2rGTNmqFWrVsrNzVVgYOBlP0teXp7y8vJsr3Ny+MPAE2pUqqCx9zXXX2dsUN75Qm+HAwDXDVPNdBR58cUXNWfOHGVkZNi1Z2RkKDY21q4tNjZWe/bssSuLtGzZslifAQEBtoRDkqpVq6bIyEi75KFatWp25ZOtW7eqW7duql27toKCgtS+fXtJ0sGDBx36HMnJyQoJCbEd4eHhDl0H1zSpXUlVgv21YvQdynq1p7Je7ak/N6iixA71lfVqT/mwLhkmVzk0UL6+PsUWjf5yIkdVKwd7KSq4G+UVD2nXrp06d+6s0aNHX9H1FStWLNZWvnx5u9cWi6XEtsLCC/8yPn36tDp37qzg4GDNnz9fmzdv1tKlSyU5vjh19OjRys7Oth2HDh26ko8DJ23cfUydkj7TPS+ssh3fHDihZZsP6p4XVqnQ8HaEgGv8ypdT84bhWrc509ZWWFio9Zu/V6smdbwYGdzJjEmH6corRSZNmqTmzZsrKur/F0pFR0dr48aNdudt3LhRDRo0kK+vr1vH3717t44fP65JkybZZii2bNniVB9Wq1VWq9WtceHyTued1/dH7EtZv58r0MnT54q1A2b1WP/b9diEebo5urZaNIrUrHfX6PTveRrQ7c/eDg1uYrFcOFy53tNMm3Q0adJEAwYM0IwZM2xtw4cPV6tWrZSUlKQ+ffooPT1dr776ql5//XW3j1+7dm35+flp5syZeuSRR7Rz504lJSW5fRwAuBI9O92iX0/m6oXZH+rY8VNq0qCm3p/xOOUVeJVpkw5JmjhxohYtWmR73aJFCy1evFhjx45VUlKSatSooYkTJ5bJjpIqVaooLS1Nf//73zVjxgy1aNFCkydP1r333uv2sVD2+k5b5+0QALd7qHd7PdS7vbfDQBm5MNPhyrNX3BiMo2MahkEF+yqRk5OjkJAQVRk4Rz5+Ad4OBygTB2b18nYIQJnJyclRtcohys7OVnBw2cwqFf1dUfep9+VrLb5G0VEFeae1b0avMo31YqZcSAoAAMzH1OUVAACuV2Z8tD1JBwAAJmTG3SuUVwAAgEcw0wEAgAn5+Fjk48ItlA0v3H6ZpAMAABOivAIAAFAKZjoAADAhdq8AAACPMGN5haQDAAATMuNMB2s6AACARzDTAQCACZlxpoOkAwAAEzLjmg7KKwAAwCOY6QAAwIQscrG8IsorAADAAZRXAAAASsFMBwAAJsTuFQAA4BGUVwAAAErBTAcAACZEeQUAAHiEGcsrJB0AAJiQGWc6WNMBAAA8gpkOAADMyMXyihduSErSAQCAGVFeAQAAKAUzHQAAmBC7VwAAgEdQXgEAACgFMx0AAJgQ5RUAAOARlFcAAABKwUwHAAAmZMaZDpIOAABMiDUdAADAI8w408GaDgAA4BHMdAAAYEKUVwAAgEdQXgEAACgFMx0AAJiQRS6WV9wWieNIOgAAMCEfi0U+LmQdrlx7xWN6fEQAAHBdYqYDAAATYvcKAADwCHavAAAAj/CxuH44Y9asWWratKmCg4MVHBys1q1b6+OPP3YuZueGBAAA16NatWpp0qRJ2rp1q7Zs2aLbb79d3bt3165duxzug/IKAABmZHGxROLkpd26dbN7/fzzz2vWrFn68ssv1ahRI4f6IOkAAMCE3LWQNCcnx67darXKarVe8tqCggK99957On36tFq3bu3wmJRXAAC4joWHhyskJMR2JCcnl3rujh07FBgYKKvVqkceeURLly5VTEyMw2Mx0wEAgAlZ/vfLlesl6dChQwoODra1X2qWIyoqStu3b1d2drbef/99JSQkaN26dQ4nHiQdAACY0JXsQLn4ekm23SiO8PPzU/369SVJt9xyizZv3qzp06dr9uzZjo15RZECAIDrXmFhofLy8hw+n5kOAABMyNM3Bxs9erTuvvtu1a5dW6dOndKCBQu0du1affrppw734VDS8Z///MfhDu+9916HzwUAAFfG07dBP3bsmAYOHKijR48qJCRETZs21aeffqo777zT4T4cSjri4+Md6sxisaigoMDhwQEAgDmkpKS43IdDSUdhYaHLAwEAAPcx46PtXVrTcfbsWfn7+7srFgAA4CAzPmXW6d0rBQUFSkpKUs2aNRUYGKh9+/ZJksaMGeOWqRcAAHB5RQtJXTk8zemk4/nnn1daWppeeukl+fn52dobN26st956y63BAQCAa4fTScfcuXP1r3/9SwMGDJCvr6+tvVmzZtq9e7dbgwMAACUrKq+4cnia02s6fvzxR9vdyP6osLBQ+fn5bgkKAABcmhkXkjo90xETE6MNGzYUa3///fd18803uyUoAABw7XF6pmPs2LFKSEjQjz/+qMLCQi1ZskSZmZmaO3euVqxYURYxAgCAi1j+d7hyvac5PdPRvXt3LV++XKtWrVLFihU1duxYZWRkaPny5U7dlQwAAFw5M+5euaL7dLRt21YrV650dywAAOAadsU3B9uyZYsyMjIkXVjnccstt7gtKAAAcGnuerS9JzmddBw+fFj9+vXTxo0bFRoaKkk6efKk2rRpo4ULF6pWrVrujhEAAFzE00+ZdQen13QMGTJE+fn5ysjI0IkTJ3TixAllZGSosLBQQ4YMKYsYAQDANcDpmY5169Zp06ZNioqKsrVFRUVp5syZatu2rVuDAwAApfPGDb5c4XTSER4eXuJNwAoKChQWFuaWoAAAwKVdF+WVl19+WU8++aS2bNlia9uyZYuGDh2qyZMnuzU4AABQsqKFpK4cnubQTEelSpXsMqLTp0/r1ltvVblyFy4/f/68ypUrp8GDBys+Pr5MAgUAAObmUNLxyiuvlHEYAADAGWYsrziUdCQkJJR1HAAAwAlmvA36Fd8cTJLOnj2rc+fO2bUFBwe7FBAAALg2OZ10nD59WqNGjdLixYt1/PjxYu8XFBS4JTAAAFC66+LR9n/729+0evVqzZo1S1arVW+99ZYmTJigsLAwzZ07tyxiBAAAF7FYXD88zemZjuXLl2vu3Lnq0KGDBg0apLZt26p+/fqKiIjQ/PnzNWDAgLKIEwAAmJzTMx0nTpxQ3bp1JV1Yv3HixAlJ0m233ab169e7NzoAAFAiMz7a3umko27dutq/f78kqWHDhlq8eLGkCzMgRQ+AAwAAZcuM5RWnk45Bgwbpm2++kSQ9++yzeu211+Tv769nnnlGI0eOdHuAAADg2uD0mo5nnnnG9vu4uDjt3r1bW7duVf369dW0aVO3BgcAAEpmxt0rLt2nQ5IiIiIUERHhjlgAAICDXC2RXLW7V2bMmOFwh0899dQVBwMAABxzzd4Gfdq0aQ51ZrFYSDoAAECJHEo6inarwDNytn0hi6+ft8MAysRf3qrt7RCAMpP/e67HxvLRFewGueh6T3N5TQcAAPA8M5ZXvJHoAACA6xAzHQAAmJDFIvlci7tXAADA1cXHxaTDlWuveEzPDwkAAK5HV5R0bNiwQffff79at26tH3/8UZI0b948ffHFF24NDgAAlOy6eODbBx98oM6dO6tChQratm2b8vLyJEnZ2dl64YUX3B4gAAAorqi84srh8ZidveCf//yn3njjDb355psqX768rT02NlZff/21W4MDAADXDqcXkmZmZqpdu3bF2kNCQnTy5El3xAQAAC7DjM9ecXqmo3r16srKyirW/sUXX6hu3bpuCQoAAFxa0VNmXTk8HrOzFzz44IMaOnSo/vvf/8pisejIkSOaP3++RowYoUcffbQsYgQAABfxccPhaU6XV5599lkVFhbqjjvu0JkzZ9SuXTtZrVaNGDFCTz75ZFnECAAArgFOJx0Wi0XPPfecRo4cqaysLOXm5iomJkaBgYFlER8AACiBGdd0XPEdSf38/BQTE+POWAAAgIN85Nq6DB95PutwOuno2LHjJW8osnr1apcCAgAA1yank47mzZvbvc7Pz9f27du1c+dOJSQkuCsuAABwCddFeWXatGklto8fP165ubkuBwQAAC7vun7g2/3336+3337bXd0BAIBrjNsebZ+eni5/f393dQcAAC7BYpFLC0lNUV7p2bOn3WvDMHT06FFt2bJFY8aMcVtgAACgdNfFmo6QkBC71z4+PoqKitLEiRPVqVMntwUGAACuLU4lHQUFBRo0aJCaNGmiSpUqlVVMAADgMq75haS+vr7q1KkTT5MFAMDLLG745WlO715p3Lix9u3bVxaxAAAABxXNdLhyeDxmZy/45z//qREjRmjFihU6evSocnJy7A4AAICSOLymY+LEiRo+fLjuueceSdK9995rdzt0wzBksVhUUFDg/igBAIAdM67pcDjpmDBhgh555BGtWbOmLOMBAAAOsFgsl3wWmiPXe5rDSYdhGJKk9u3bl1kwAADg2uXUlllvZEUAAKC4a7q8IkkNGjS4bOJx4sQJlwICAACXd83fkXTChAnF7kgKAADgCKeSjr59+6pq1aplFQsAAHCQj8Xi0gPfXLn2isd09ETWcwAAcPXw9M3BkpOT1apVKwUFBalq1aqKj49XZmamczE7emLR7hUAAHD9WbdunR5//HF9+eWXWrlypfLz89WpUyedPn3a4T4cLq8UFhZeUZAAAKAMuLiQ1NlHr3zyySd2r9PS0lS1alVt3bpV7dq1c6gPpx9tDwAAvM9HFvm48NC2omsvfoSJ1WqV1Wq97PXZ2dmSpBtuuMGJMQEAgOkUbZl15ZCk8PBwhYSE2I7k5OTLjl1YWKinn35asbGxaty4scMxM9MBAMB17NChQwoODra9dmSW4/HHH9fOnTv1xRdfODUWSQcAACbkrjuSBgcH2yUdl/PEE09oxYoVWr9+vWrVquXUmCQdAACYkKfv02EYhp588kktXbpUa9euVZ06dZwek6QDAABc1uOPP64FCxbo3//+t4KCgvTTTz9JkkJCQlShQgWH+mAhKQAAJuSuhaSOmjVrlrKzs9WhQwfVqFHDdixatMjhPpjpAADAhHzkYnnFye227rhJKDMdAADAI5jpAADAhK75R9sDAICrg49cK1d4o9RBeQUAAHgEMx0AAJiQxWKRxYUaiSvXXimSDgAATMgipx8UW+x6TyPpAADAhDx9R1J3YE0HAADwCGY6AAAwKW+USFxB0gEAgAmZ8T4dlFcAAIBHMNMBAIAJsWUWAAB4BHckBQAAKAUzHQAAmBDlFQAA4BFmvCMp5RUAAOARzHQAAGBClFcAAIBHmHH3CkkHAAAmZMaZDtZ0AAAAj2CmAwAAEzLj7hWSDgAATIgHvgEAAJSCmQ4AAEzIRxb5uFAkceXaK0XSAQCACVFeAQAAKAUzHQAAmJDlf79cud7TSDoAADAhyisAAAClYKYDAAATsri4e4XyCgAAcIgZyyskHQAAmJAZkw7WdAAAAI9gpgMAABNiyywAAPAIH8uFw5XrPY3yCgAA8AhmOgAAMCHKKwAAwCPYvQIAAFAKZjoAADAhi1wrkXhhooOkAwAAM2L3CgAAQCmY6XBBZGSknn76aT399NPeDgVOGPXgPXr2oXvs2r4/8JNuve+fXooIcK/O0VXVObqqqgRaJUmHfvtd7237UdsOZ3s5MrgTu1euUHp6um677Tbddddd+vDDD70dDq4DGXuPKP7xmbbX588XejEawL2Onz6nd746pKM5ZyVZ1LHBjRp1500auXSXDp383dvhwU3YvXKFUlJS9OSTT2r9+vU6cuSIt8PBdeB8QaGOHT9lO05kn/Z2SIDbbDl4Ul8fztbRnDwdzTmrBVsO62x+oRpUrejt0OBGFjccnub1pCM3N1eLFi3So48+qi5duigtLc323tq1a2WxWPT555+rZcuWCggIUJs2bZSZmWnXx6xZs1SvXj35+fkpKipK8+bNs3vfYrFo9uzZ6tq1qwICAhQdHa309HRlZWWpQ4cOqlixotq0aaO9e/fartm7d6+6d++uatWqKTAwUK1atdKqVatK/RyDBw9W165d7dry8/NVtWpVpaSkuPANoSzUDa+i7z56XtuWjde/khJUq1olb4cElAkfixRb9wb5l/dR5rFcb4eD65zXk47FixerYcOGioqK0v3336+3335bhmHYnfPcc89pypQp2rJli8qVK6fBgwfb3lu6dKmGDh2q4cOHa+fOnXr44Yc1aNAgrVmzxq6PpKQkDRw4UNu3b1fDhg3Vv39/Pfzwwxo9erS2bNkiwzD0xBNP2M7Pzc3VPffco88//1zbtm3TXXfdpW7duungwYMlfo4hQ4bok08+0dGjR21tK1as0JkzZ9SnT58Sr8nLy1NOTo7dgbK3ddcBPT7hHd331GsaPmmRIsIq66M3n1FggNXboQFuU7tSBb2TcIsWDmqlh2Mj9dLKPTp88qy3w4Ib+cgiH4sLhxfmOryedKSkpOj++++XJN11113Kzs7WunXr7M55/vnn1b59e8XExOjZZ5/Vpk2bdPbshf94Jk+erMTERD322GNq0KCBhg0bpp49e2ry5Ml2fQwaNEi9e/dWgwYNNGrUKB04cEADBgxQ586dFR0draFDh2rt2rW285s1a6aHH35YjRs31k033aSkpCTVq1dP//nPf0r8HG3atCk2y5Kamqr77rtPgYGBJV6TnJyskJAQ2xEeHu709wfnrdr0nf79+Tbtyjqi1V9m6L6hsxQSVEHxcS28HRrgNkeyz2rE0p169t+79GnGMT3Rvq5qhfp7Oyy4EeUVJ2VmZuqrr75Sv379JEnlypVTnz59ipUjmjZtavt9jRo1JEnHjh2TJGVkZCg2Ntbu/NjYWGVkZJTaR7Vq1SRJTZo0sWs7e/asbbYhNzdXI0aMUHR0tEJDQxUYGKiMjIxSZzqkC7MdqampkqSff/5ZH3/8sd2szMVGjx6t7Oxs23Ho0KFSz0XZycn9XVkHj6lueBVvhwK4zflCQz/l5Gnf8TOav+WwfjhxRl0aVfd2WLjOeXX3SkpKis6fP6+wsDBbm2EYslqtevXVV21t5cuXt/3e8r/ltoWFzu02KKmPS/U7YsQIrVy5UpMnT1b9+vVVoUIF9erVS+fOnSt1jIEDB+rZZ59Venq6Nm3apDp16qht27alnm+1WmW1MqXvbRUr+KlOzRu16NevvB0KUGYsFovK+3rj37YoM65OV3jhx8FrScf58+c1d+5cTZkyRZ06dbJ7Lz4+Xu+++64aNmx42X6io6O1ceNGJSQk2No2btyomJgYl+LbuHGjEhMT1aNHD0kXZj4OHDhwyWsqV66s+Ph4paamKj09XYMGDXIpBpSNiUN76JMNO3To6AnVqBKiZx/qooLCQn3w6VZvhwa4xYCWtbTtcLZ+yc1ThfK+aluvshrVCFLSJ+wOvJZwnw4nrFixQr/99pseeOABhYSE2L33l7/8RSkpKXr55Zcv28/IkSPVu3dv3XzzzYqLi9Py5cu1ZMmSS+40ccRNN92kJUuWqFu3brJYLBozZoxDsytDhgxR165dVVBQYJcI4epRs2qo3vrnIN0QEqBff8vVf7/ZpzsHTdHxk6zsx7UhpEJ5Pdm+rioFlNeZcwX64cQZJX2SqW9/ZLE6vMtrSUdKSori4uKKJRzShaTjpZde0rfffnvZfuLj4zV9+nRNnjxZQ4cOVZ06dZSamqoOHTq4FN/UqVM1ePBgtWnTRjfeeKNGjRrl0O6SuLg41ahRQ40aNbIrG+Hq8cBzqd4OAShTr2/Y7+0Q4Aku3hzMG+UVi3Hx/lS4JDc3VzVr1lRqaqp69uzp1LU5OTkKCQmRtcmDsvj6lVGEgHfd/vBAb4cAlJn833O1ctgdys7OVnBwcJmMUfR3xertBxUYdOVj5J7K0e3Na5dprBe7Km6Dfi0oLCzUr7/+qilTpig0NFT33nuvt0MCAOCqQtLhJgcPHlSdOnVUq1YtpaWlqVw5vloAQBli98r1KzIystidVAEAKCvsXgEAAB7BU2YBAABKwUwHAAAmZMIlHSQdAACYkgmzDsorAADAI0g6AAAwIYsbfjlj/fr16tatm8LCwmSxWLRs2TKnYybpAADAhIp2r7hyOOP06dNq1qyZXnvttSuOmTUdAADgsu6++27dfffdLvVB0gEAgAm5ax3pxQ8ztVqtslqtLvRcOsorAACYkcUNh6Tw8HCFhITYjuTk5DILmZkOAACuY4cOHbJ7ymxZzXJIJB0AAJiSu569EhwczKPtAQBA6cz47BWSDgAATMjTNyTNzc1VVlaW7fX+/fu1fft23XDDDapdu7ZDfZB0AACAy9qyZYs6duxoez1s2DBJUkJCgtLS0hzqg6QDAAAz8vBUR4cOHWQYhgsDknQAAGBK7lpI6kncpwMAAHgEMx0AAJgQu1cAAIBHeHr3ijtQXgEAAB7BTAcAAGZkwqkOkg4AAEyI3SsAAAClYKYDAAATYvcKAADwCBMu6SDpAADAlEyYdbCmAwAAeAQzHQAAmJAZd6+QdAAAYEYuLiSlvAIAAK5ZzHQAAGBCJlxHStIBAIApmTDroLwCAAA8gpkOAABMiN0rAADAI8x4G3TKKwAAwCOY6QAAwIRMuI6UpAMAAFMyYdZB0gEAgAmZcSEpazoAAIBHMNMBAIAJWeTi7hW3ReI4kg4AAEzIhEs6KK8AAADPYKYDAAATMuPNwUg6AAAwJfMVWCivAAAAj2CmAwAAE6K8AgAAPMJ8xRXKKwAAwEOY6QAAwIQorwAAAI8w47NXSDoAADAjEy7qYE0HAADwCGY6AAAwIRNOdJB0AABgRmZcSEp5BQAAeAQzHQAAmBC7VwAAgGeYcFEH5RUAAOARzHQAAGBCJpzoIOkAAMCM2L0CAABQCmY6AAAwJdd2r3ijwELSAQCACVFeAQAAKAVJBwAA8AjKKwAAmJAZyyskHQAAmJAZb4NOeQUAAHgEMx0AAJgQ5RUAAOARZrwNOuUVAADgEcx0AABgRiac6iDpAADAhNi9AgAAUApmOgAAMCF2rwAAAI8w4ZIOyisAAJiSxQ3HFXjttdcUGRkpf39/3Xrrrfrqq68cvpakAwAAOGTRokUaNmyYxo0bp6+//lrNmjVT586ddezYMYeuJ+kAAMCELG745aypU6fqwQcf1KBBgxQTE6M33nhDAQEBevvttx26nqQDAAATKlpI6srhjHPnzmnr1q2Ki4uztfn4+CguLk7p6ekO9cFC0quIYRgX/rfgnJcjAcpO/u+53g4BKDPnz56W9P9/npelnJwct1x/cT9Wq1VWq7XY+b/++qsKCgpUrVo1u/Zq1app9+7dDo1J0nEVOXXqlCTp3HdzvBwJUHZWDnvT2yEAZe7UqVMKCQkpk779/PxUvXp13VQn3OW+AgMDFR5u38+4ceM0fvx4l/suCUnHVSQsLEyHDh1SUFCQLN7YQH0dysnJUXh4uA4dOqTg4GBvhwO4FT/fnmcYhk6dOqWwsLAyG8Pf31/79+/XuXOuz4obhlHs75uSZjkk6cYbb5Svr69+/vlnu/aff/5Z1atXd2g8ko6riI+Pj2rVquXtMK5LwcHB/KGMaxY/355VVjMcf+Tv7y9/f/8yH+eP/Pz8dMstt+jzzz9XfHy8JKmwsFCff/65nnjiCYf6IOkAAAAOGTZsmBISEtSyZUv96U9/0iuvvKLTp09r0KBBDl1P0gEAABzSp08f/fLLLxo7dqx++uknNW/eXJ988kmxxaWlIenAdc1qtWrcuHGl1jABM+PnG2XhiSeecLiccjGL4Yl9PQAA4LrHzcEAAIBHkHQAAACPIOkAAAAeQdIBlIG1a9fKYrHo5MmT3g4FcJvIyEi98sor3g4DJkbSgateYmKiLBaLJk2aZNe+bNky7twKU0pPT5evr6+6dOni7VAAjyLpgCn4+/vrxRdf1G+//ea2Pt1xC2HgSqSkpOjJJ5/U+vXrdeTIEW+HA3gMSQdMIS4uTtWrV1dycnKp53zwwQdq1KiRrFarIiMjNWXKFLv3IyMjlZSUpIEDByo4OFgPPfSQ0tLSFBoaqhUrVigqKkoBAQHq1auXzpw5ozlz5igyMlKVKlXSU089pYKCAltf8+bNU8uWLRUUFKTq1aurf//+OnbsWJl9flw7cnNztWjRIj366KPq0qWL0tLSbO8VleU+//xztWzZUgEBAWrTpo0yMzPt+pg1a5bq1asnPz8/RUVFad68eXbvWywWzZ49W127dlVAQICio6OVnp6urKwsdejQQRUrVlSbNm20d+9e2zV79+5V9+7dVa1aNQUGBqpVq1ZatWpVqZ9j8ODB6tq1q11bfn6+qlatqpSUFBe+IVzTDOAql5CQYHTv3t1YsmSJ4e/vbxw6dMgwDMNYunSpUfQjvGXLFsPHx8eYOHGikZmZaaSmphoVKlQwUlNTbf1EREQYwcHBxuTJk42srCwjKyvLSE1NNcqXL2/ceeedxtdff22sW7fOqFy5stGpUyejd+/exq5du4zly5cbfn5+xsKFC219paSkGB999JGxd+9eIz093WjdurVx9913295fs2aNIcn47bffPPIdwTxSUlKMli1bGoZhGMuXLzfq1atnFBYWGobx/z83t956q7F27Vpj165dRtu2bY02bdrYrl+yZIlRvnx547XXXjMyMzONKVOmGL6+vsbq1att50gyatasaSxatMjIzMw04uPjjcjISOP22283PvnkE+O7774z/vznPxt33XWX7Zrt27cbb7zxhrFjxw7j+++/N/7xj38Y/v7+xg8//GA7JyIiwpg2bZphGIaxceNGw9fX1zhy5IhdbBUrVjROnTpVJt8dzI+kA1e9oqTDMAzjz3/+szF48GDDMOyTjv79+xt33nmn3XUjR440YmJibK8jIiKM+Ph4u3NSU1MNSUZWVpat7eGHHzYCAgLs/uDs3Lmz8fDDD5ca4+bNmw1JtmtIOlCaNm3aGK+88ophGIaRn59v3HjjjcaaNWsMw/j/n5tVq1bZzv/www8NScbvv/9uu/7BBx+06/O+++4z7rnnHttrScY//vEP2+v09HRDkpGSkmJre/fddw1/f/9LxtqoUSNj5syZttd/TDoMwzBiYmKMF1980fa6W7duRmJi4uW+AlzHKK/AVF588UXNmTNHGRkZdu0ZGRmKjY21a4uNjdWePXvsyiItW7Ys1mdAQIDq1atne12tWjVFRkYqMDDQru2P5ZOtW7eqW7duql27toKCgtS+fXtJ0sGDB137gLimZWZm6quvvlK/fv0kSeXKlVOfPn2KlSOaNm1q+32NGjUkyfbzV9rP+sX/Tfyxj6LnYjRp0sSu7ezZs8rJyZF0oewzYsQIRUdHKzQ0VIGBgcrIyLjkz/SQIUOUmpoq6cLjzT/++GMNHjzYgW8C1yuSDphKu3bt1LlzZ40ePfqKrq9YsWKxtvLly9u9tlgsJbYVFhZKkk6fPq3OnTsrODhY8+fP1+bNm7V06VJJLE7FpaWkpOj8+fMKCwtTuXLlVK5cOc2aNUsffPCBsrOzbef98eevaIdW0c+fo0rq41L9jhgxQkuXLtULL7ygDRs2aPv27WrSpMklf6YHDhyoffv2KT09Xe+8847q1Kmjtm3bOhUnri888A2mM2nSJDVv3lxRUVG2tujoaG3cuNHuvI0bN6pBgwby9fV16/i7d+/W8ePHNWnSJIWHh0uStmzZ4tYxcO05f/685s6dqylTpqhTp05278XHx+vdd99Vw4YNL9tP0c96QkKCrW3jxo2KiYlxKb6NGzcqMTFRPXr0kHRh5uPAgQOXvKZy5cqKj49Xamqq0tPTHX68Oa5fJB0wnSZNmmjAgAGaMWOGrW348OFq1aqVkpKS1KdPH6Wnp+vVV1/V66+/7vbxa9euLT8/P82cOVOPPPKIdu7cqaSkJLePg2vLihUr9Ntvv+mBBx5QSEiI3Xt/+ctflJKSopdffvmy/YwcOVK9e/fWzTffrLi4OC1fvlxLliy55E4TR9x0001asmSJunXrJovFojFjxjg0uzJkyBB17dpVBQUFdokQUBLKKzCliRMn2v2B2KJFCy1evFgLFy5U48aNNXbsWE2cOFGJiYluH7tKlSpKS0vTe++9p5iYGE2aNEmTJ092+zi4tqSkpCguLq5YwiFdSDq2bNmib7/99rL9xMfHa/r06Zo8ebIaNWqk2bNnKzU1VR06dHApvqlTp6pSpUpq06aNunXrps6dO6tFixaXvS4uLk41atRQ586dFRYW5lIMuPbxaHsAwBXLzc1VzZo1lZqaqp49e3o7HFzlKK8AAJxWWFioX3/9VVOmTFFoaKjuvfdeb4cEEyDpAAA47eDBg6pTp45q1aqltLQ0lSvHXye4PMorAADAI1hICgAAPIKkAwAAeARJBwAA8AiSDgAA4BEkHQDsJCYmKj4+3va6Q4cOevrppz0ex9q1a2WxWHTy5MlSz7FYLFq2bJnDfY4fP17Nmzd3Ka4DBw7IYrFo+/btLvUDXI9IOgATSExMlMVikcVikZ+fn+rXr6+JEyfq/PnzZT72kiVLHL7NuyOJAoDrFxurAZO46667lJqaqry8PH300Ud6/PHHVb58+RKfuHvu3Dn5+fm5ZdwbbrjBLf0AADMdgElYrVZVr15dERERevTRRxUXF6f//Oc/kv6/JPL8888rLCzM9gTeQ4cOqXfv3goNDdUNN9yg7t272z05tKCgQMOGDVNoaKgqV66sv/3tb7r41j0Xl1fy8vI0atQohYeHy2q1qn79+kpJSdGBAwfUsWNHSVKlSpVksVhsz74pLCxUcnKy6tSpowoVKqhZs2Z6//337cb56KOP1KBBA1WoUEEdO3a87BNOSzJq1Cg1aNBAAQEBqlu3rsaMGaP8/Pxi582ePVvh4eEKCAhQ79697R4rL0lvvfWWoqOj5e/vr4YNG5bJgwOB6xFJB2BSFSpU0Llz52yvP//8c2VmZmrlypVasWKF8vPz1blzZwUFBWnDhg3auHGjAgMDddddd9mumzJlitLS0vT222/riy++0IkTJ7R06dJLjjtw4EC9++67mjFjhjIyMjR79mwFBgYqPDxcH3zwgSQpMzNTR48e1fTp0yVJycnJmjt3rt544w3t2rVLzzzzjO6//36tW7dO0oXkqGfPnurWrZu2b9+uIUOG6Nlnn3X6OwkKClJaWpq+++47TZ8+XW+++aamTZtmd05WVpYWL16s5cuX65NPPtG2bdv02GOP2d6fP3++xo4dq+eff14ZGRl64YUXNGbMGM2ZM8fpeABcxABw1UtISDC6d+9uGIZhFBYWGitXrjSsVqsxYsQI2/vVqlUz8vLybNfMmzfPiIqKMgoLC21teXl5RoUKFYxPP/3UMAzDqFGjhvHSSy/Z3s/Pzzdq1aplG8swDKN9+/bG0KFDDcMwjMzMTEOSsXLlyhLjXLNmjSHJ+O2332xtZ8+eNQICAoxNmzbZnfvAAw8Y/fr1MwzDMEaPHm3ExMTYvT9q1KhifV1MkrF06dJS33/55ZeNW265xfZ63Lhxhq+vr3H48GFb28cff2z4+PgYR48eNQzDMOrVq2csWLDArp+kpCSjdevWhmEYxv79+w1JxrZt20odF0DJWNMBmMSKFSsUGBio/Px8FRYWqn///ho/frzt/SZNmtit4/jmm2+UlZWloKAgu37Onj2rvXv3Kjs7W0ePHtWtt95qe69cuXJq2bJlsRJLke3bt8vX11ft27d3OO6srCydOXNGd955p137uXPndPPNN0uSMjIy7OKQpNatWzs8RpFFixZpxowZ2rt3r3Jzc3X+/HkFBwfbnVO7dm3VrFnTbpzCwkJlZmYqKChIe/fu1QMPPKAHH3zQds758+dLfCQ9AOeQdAAm0bFjR82aNUt+fn4KCwsr9oCtihUr2r3Ozc3VLbfcovnz5xfrq0qVKlcUQ4UKFZy+Jjc3V5L04Ycf2v1lL11Yp+Iu6enpGjBggCZMmKDOnTsrJCRECxcu1JQpU5yO9c033yyWBPn6+rotVuB6RdIBmETFihVVv359h89v0aKFFi1apKpVqxb7136RGjVq6L///a/atWsn6cK/6Ldu3aoWLVqUeH6TJk1UWFiodevWKS4urtj7RTMtBQUFtraYmBhZrVYdPHiw1BmS6Oho26LYIl9++eXlP+QfbNq0SREREXruuedsbT/88EOx8w4ePKgjR44oLCzMNo6Pj4+ioqJUrVo1hYWFad++fRowYIBT4wO4PBaSAteoAQMG6MYbb1T37t21YcMG7d+/X2vXrtVTTz2lw4cPS5KGDh2qSZMmadmyZdq9e7cee+yxS95jIzIyUgkJCRo8eLCWLVtm63Px4sWSpIiICFksFq1YsUK//PKLcnNzFRQUpBEjRuiZZ57RnDlztHfvXn399deaOXOmbXHmI488oj179mjkyJHKzMzUggULlJaW5tTnvemmm3Tw4EEtXLhQe/fu1YwZM0pcFOvv76+EhAR988032rBhg5566in17t1b1atXlyRNmDBBycnJmjFjhr7//nvt2LFDqampmjp1qlPxACiOpAO4RgUEBGj9+vWqXbu2evbsqejoaD3wwAM6e/asbeZj+PDh+utf/6qEhAS1bt1aQUFB6tGjxyX7nTVrlnr16qXHHntMDRs21IMPPqjTp09LkmrWrKkJEybo2WefVbVq1fTEE09IkpKSkjRmzBglJycrOjpad911lz788EPVqVNH0oV1Fh988IGWLVumZs2a6Y033tALL7zg1Oe999579cwzz+iJJ55Q8+bNtWnTJo0ZM6bYefXr11fPnj11zz33qFOnTmratKndltghQ4borbfeUmpqqpo0aaL27dsrLS3NFiuAK2cxSlsxBgAA4EbMdAAAAI8g6QAAAB5B0gEAADyCpAMAAHgESQcAAPAIkg4AAOARJB0AAMAjSDoAAIBHkHQAAACPIOkAAAAeQdIBAAA8gqQDAAB4xP8BN/LW6tots30AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_root = Path(\"val/\")\n",
    "output_root = Path(\"val_out/\")\n",
    "output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "all_preds = []\n",
    "all_actuals = []\n",
    "\n",
    "fps = 10\n",
    "\n",
    "for folder in sorted(dataset_root.iterdir()):\n",
    "    if folder.is_dir():\n",
    "        print(f\"Processing folder: {folder.name}\")\n",
    "        ds = STUDataset(folder, single_scene=True)\n",
    "        ds_iter = iter_ds(ds, window_size=50, step_size=20, video_output_path=\"output_video.mp4\", fps=fps)\n",
    "        \n",
    "        preds = []\n",
    "        actuals = []\n",
    "\n",
    "        # ======== Video for each scene ============ \n",
    "        width, height = ds.image_width, ds.image_height\n",
    "        # Define the codec and create VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can use other codecs as well\n",
    "        video_writer = cv2.VideoWriter(output_root/f\"{folder.name}_out.mp4\", fourcc, fps, (width, height))\n",
    "        # ================================================\n",
    "        \n",
    "\n",
    "        n_samples = (len(ds) - 50)/20 + 1\n",
    "        for i, sample in enumerate(ds_iter):\n",
    "            result = process_and_run()\n",
    "            # print(result)\n",
    "            anomaly = \"Classification: Anomaly\" in result\n",
    "            actuals.append(sample[1])\n",
    "            preds.append(anomaly)\n",
    "            \n",
    "            print(f\"\\tActual: {sample[1]}, Predicted: {anomaly} ---- [{i+1}/{n_samples}]\")\n",
    "\n",
    "            # Append images to video\n",
    "            images = sample[2]\n",
    "            for img in images:\n",
    "                # Convert PIL Image to OpenCV format\n",
    "                img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Write prediction and actual on the image\n",
    "                # Put text on rectangle background in the top-center\n",
    "                # Make rectangle green if prediction is correct, red otherwise\n",
    "                if anomaly == sample[1]:\n",
    "                    rect_color = (0, 255, 0)  # Green\n",
    "                else:\n",
    "                    rect_color = (0, 0, 255)  # Red\n",
    "                cv2.rectangle(img_cv, (width//2 - 400, 30), (width//2 + 400, 140), rect_color, -1)\n",
    "                cv2.putText(\n",
    "                    img_cv,\n",
    "                    f\"Predicted: {anomaly} | Actual: {sample[1]}\",\n",
    "                    (width//2 - 360, 100),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.5,\n",
    "                    (255, 255, 255),\n",
    "                    3,\n",
    "                )\n",
    "                \n",
    "                # put next text on a transparent black rectangle\n",
    "                \n",
    "                cv2.putText(img_cv, f\"Sample Num: {i+1}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                video_writer.write(img_cv)\n",
    "        video_writer.release()\n",
    "        print(f\"Processed video saved at {output_root/f'{folder.name}_out.mp4'}\")\n",
    "        \n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_actuals.extend(actuals)\n",
    "        compute_metrics(preds, actuals)\n",
    "    break\n",
    "\n",
    "print(\"Overall Metrics:\")\n",
    "compute_metrics(all_preds, all_actuals)\n",
    "plot_confusion_matrix(all_preds, all_actuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8506a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cp \"val_out/125_out.mp4\" /mnt/c/Users/adeju/Downloads/output_video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074b8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Accuracy: 58.33%\n",
      "==============================\n",
      "Precision: 100.00%\n",
      "Recall: 37.50%\n",
      "F1-score: 54.55%\n",
      "==============================\n",
      "True Positives: 3\n",
      "False Positives: 0\n",
      "True Negatives: 4\n",
      "False Negatives: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Accuracy calculation\n",
    "# correct = sum(p == a for p, a in zip(predictions, actuals))\n",
    "# accuracy = correct / len(actuals) if actuals else 0\n",
    "# print(\"=\"*30)\n",
    "# print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# # Computer precision, recall, F1-score\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# precision = precision_score(actuals, predictions)\n",
    "# recall = recall_score(actuals, predictions)\n",
    "# f1 = f1_score(actuals, predictions)\n",
    "# print(\"=\"*30)\n",
    "# print(f\"Precision: {precision * 100:.2f}%\")\n",
    "# print(f\"Recall: {recall * 100:.2f}%\")\n",
    "# print(f\"F1-score: {f1 * 100:.2f}%\")\n",
    "\n",
    "# # True Positives, False Positives, True Negatives, False Negatives\n",
    "# tp = sum((p == 1) and (a == 1) for p, a in zip(predictions, actuals))\n",
    "# fp = sum((p == 1) and (a == 0) for p, a in zip(predictions, actuals))\n",
    "# tn = sum((p == 0) and (a == 0) for p, a in zip(predictions, actuals))\n",
    "# fn = sum((p == 0) and (a == 1) for p, a in zip(predictions, actuals))\n",
    "# print(\"=\"*30)\n",
    "# print(f\"True Positives: {tp}\")\n",
    "# print(f\"False Positives: {fp}\")\n",
    "# print(f\"True Negatives: {tn}\")\n",
    "# print(f\"False Negatives: {fn}\")\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# cm = np.array([[tn, fp], [fn, tp]])\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Anomaly\"])\n",
    "# disp.plot(cmap=plt.cm.Blues)\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e36ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cp -r val/125/* cosmos_val/101/  || sudo mv val/126/* cosmos_val/101/\n",
    "\n",
    "sudo mv cosmos_val/101/* val/126/\n",
    "\n",
    "sudo rm -rf cosmos_val/101/*\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffca57b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = \"\"\"“You are an autonomous driving safety and perception expert analyzing this video for potential EXTERNAL ANOMALIES that could affect the safe and predictable operation of an autonomous vehicle.\n",
    "\n",
    "<think>\n",
    "\"CRITICAL ANOMALIES:\\n\"\n",
    "- Unexpected obstacles on or near the roadway (debris, animals, fallen objects)\n",
    "- Pedestrians or cyclists entering or approaching the vehicle’s path\n",
    "- Vehicles violating traffic rules (red-light running, wrong-way driving, illegal turns)\n",
    "- Close calls or near-collision situations involving any road user\n",
    "- Road work zones, blocked lanes, or temporary cones\n",
    "- Emergency vehicles or flashing lights impacting traffic flow\n",
    "- Missing, obscured, or malfunctioning traffic signals/signs\n",
    "- Road surface hazards (potholes, water puddles, ice, uneven terrain)\n",
    "- Stopped or stalled vehicles obstructing lanes\n",
    "- Unusual or unpredictable movement of surrounding objects or road users\n",
    "\"CONTEXT MISINTERPRETATION ANOMALIES:\"\n",
    "- Situations where the vehicle might misclassify or misinterpret visual cues\n",
    "    (e.g., a person wearing clothing with a STOP sign print mistaken for a real traffic sign)\n",
    "- False positives due to reflections, shadows, or advertisements resembling real road objects\n",
    "- Unclear or deceptive visual context (e.g., temporary paint, digital displays, mirrored surfaces)\n",
    "- Any environment where perception sensors might interpret context incorrectly and trigger false actions\n",
    "\"OTHER SAFETY CONCERNS:\"\n",
    "- Speeding or aggressive driving by surrounding vehicles\n",
    "- Unsafe lane changes, tailgating, or sudden stops\n",
    "- Faded or missing lane markings\n",
    "- Poor visibility (fog, glare, heavy rain, low light)\n",
    "- Overcrowded intersections or congested roadways\n",
    "- Objects falling from moving vehicles (cargo, equipment)\n",
    "- Environmental interference (smoke, dust, reflections)\n",
    "- Any condition likely to reduce sensor or perception reliability\n",
    "Analyze the video carefully and identify all external anomalies and context-related perception issues that could cause unsafe or unpredictable autonomous vehicle behavior.Focus especially on how environmental context could lead to false detection or unsafe reaction.\n",
    "</think>\n",
    "<answer>\n",
    "Is there any external anomaly  in this video? \n",
    "</answer>”\n",
    "\"\"\"\n",
    "\n",
    "len(b.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a1035cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = \"\"\"“I am the fault monitor for a vision-based autonomous vehicle. My job is to analyze the vehicle’s observations and identify anything that could cause the vehicle to take actions that are unsafe, unpredictable or violate traffic rules. For each object that the vehicle observes, I will reason about whether the object constitutes a normal observation or an anomaly. Normal observations do not detrimentally affect the vehicle’s performance, whereas anomalies might. Finally, I will classify whether the overall scene is normal or abnormal.\n",
    "\n",
    "<think>\n",
    "1. Is this common to see while driving?\n",
    "2. Can this influence the vehicle’s behavior?\n",
    "3. Can the vehicle drive safely in its presence?\n",
    "4. Can this cause the vehicle to make unpredictable or unsafe maneuvers?\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "Give your classification as 'Classification: Normal' or 'Classification: Anomaly'\n",
    "</answer>”\n",
    "\"\"\"\n",
    "\n",
    "len(c.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "def terminal_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a3e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/Dev/ms_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Dev/ms_proj/cosmos-reason1/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68efc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/Dev/ms_proj/stu_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Dev/ms_proj/cosmos-reason1/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../../stu_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8721e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ./output_videos/ ~/Dev/cosmos_fp4_quantization/output_videos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fee4a763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output videos will be saved to: /home/daniel/Dev/ms_proj/stu_dataset/output_videos\n",
      "Processing folder: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Dev/ms_proj/stu_dataset/stu_video_dataset.py:113: RuntimeWarning: invalid value encountered in cast\n",
      "  pts_int = image_points.astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing video to output_videos/scene_125_30.mp4\n",
      "output_videos/scene_125_30.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_30.mp4\n",
      "output_videos/scene_125_30.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_30.mp4\n",
      "Writing video to output_videos/scene_125_50.mp4\n",
      "Writing video to output_videos/scene_125_50.mp4\n",
      "output_videos/scene_125_50.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_50.mp4\n",
      "output_videos/scene_125_50.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_50.mp4\n",
      "Writing video to output_videos/scene_125_70.mp4\n",
      "Writing video to output_videos/scene_125_70.mp4\n",
      "output_videos/scene_125_70.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_70.mp4\n",
      "output_videos/scene_125_70.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_70.mp4\n",
      "Writing video to output_videos/scene_125_90.mp4\n",
      "Writing video to output_videos/scene_125_90.mp4\n",
      "output_videos/scene_125_90.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_90.mp4\n",
      "output_videos/scene_125_90.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_90.mp4\n",
      "Writing video to output_videos/scene_125_110.mp4\n",
      "Writing video to output_videos/scene_125_110.mp4\n",
      "output_videos/scene_125_110.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_110.mp4\n",
      "output_videos/scene_125_110.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_110.mp4\n",
      "Writing video to output_videos/scene_125_130.mp4\n",
      "Writing video to output_videos/scene_125_130.mp4\n",
      "output_videos/scene_125_130.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_130.mp4\n",
      "output_videos/scene_125_130.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_130.mp4\n",
      "Writing video to output_videos/scene_125_150.mp4\n",
      "Writing video to output_videos/scene_125_150.mp4\n",
      "output_videos/scene_125_150.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_150.mp4\n",
      "output_videos/scene_125_150.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_150.mp4\n",
      "Writing video to output_videos/scene_125_170.mp4\n",
      "Writing video to output_videos/scene_125_170.mp4\n",
      "output_videos/scene_125_170.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_170.mp4\n",
      "output_videos/scene_125_170.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_170.mp4\n",
      "Writing video to output_videos/scene_125_190.mp4\n",
      "Writing video to output_videos/scene_125_190.mp4\n",
      "output_videos/scene_125_190.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_190.mp4\n",
      "output_videos/scene_125_190.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_190.mp4\n",
      "Writing video to output_videos/scene_125_210.mp4\n",
      "Writing video to output_videos/scene_125_210.mp4\n",
      "output_videos/scene_125_210.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_210.mp4\n",
      "output_videos/scene_125_210.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_210.mp4\n",
      "Writing video to output_videos/scene_125_230.mp4\n",
      "Writing video to output_videos/scene_125_230.mp4\n",
      "output_videos/scene_125_230.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_230.mp4\n",
      "Writing video to output_videos/scene_125_250.mp4\n",
      "output_videos/scene_125_230.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_230.mp4\n",
      "Writing video to output_videos/scene_125_250.mp4\n",
      "output_videos/scene_125_250.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_250.mp4\n",
      "Processing folder: 126\n",
      "output_videos/scene_125_250.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_125_250.mp4\n",
      "Processing folder: 126\n",
      "Writing video to output_videos/scene_126_30.mp4\n",
      "Writing video to output_videos/scene_126_30.mp4\n",
      "output_videos/scene_126_30.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_30.mp4\n",
      "output_videos/scene_126_30.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_30.mp4\n",
      "Writing video to output_videos/scene_126_50.mp4\n",
      "Writing video to output_videos/scene_126_50.mp4\n",
      "output_videos/scene_126_50.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_50.mp4\n",
      "output_videos/scene_126_50.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_50.mp4\n",
      "Writing video to output_videos/scene_126_70.mp4\n",
      "Writing video to output_videos/scene_126_70.mp4\n",
      "output_videos/scene_126_70.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_70.mp4\n",
      "output_videos/scene_126_70.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_70.mp4\n",
      "Writing video to output_videos/scene_126_90.mp4\n",
      "Writing video to output_videos/scene_126_90.mp4\n",
      "output_videos/scene_126_90.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_90.mp4\n",
      "output_videos/scene_126_90.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_90.mp4\n",
      "Writing video to output_videos/scene_126_110.mp4\n",
      "Writing video to output_videos/scene_126_110.mp4\n",
      "output_videos/scene_126_110.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_110.mp4\n",
      "output_videos/scene_126_110.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_110.mp4\n",
      "Writing video to output_videos/scene_126_130.mp4\n",
      "Writing video to output_videos/scene_126_130.mp4\n",
      "output_videos/scene_126_130.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_130.mp4\n",
      "output_videos/scene_126_130.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_130.mp4\n",
      "Writing video to output_videos/scene_126_150.mp4\n",
      "Writing video to output_videos/scene_126_150.mp4\n",
      "output_videos/scene_126_150.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_150.mp4\n",
      "output_videos/scene_126_150.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_150.mp4\n",
      "Writing video to output_videos/scene_126_170.mp4\n",
      "Writing video to output_videos/scene_126_170.mp4\n",
      "output_videos/scene_126_170.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_170.mp4\n",
      "output_videos/scene_126_170.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_170.mp4\n",
      "Writing video to output_videos/scene_126_190.mp4\n",
      "Writing video to output_videos/scene_126_190.mp4\n",
      "output_videos/scene_126_190.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_190.mp4\n",
      "output_videos/scene_126_190.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_190.mp4\n",
      "Writing video to output_videos/scene_126_210.mp4\n",
      "Writing video to output_videos/scene_126_210.mp4\n",
      "output_videos/scene_126_210.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_210.mp4\n",
      "output_videos/scene_126_210.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_210.mp4\n",
      "Writing video to output_videos/scene_126_230.mp4\n",
      "Writing video to output_videos/scene_126_230.mp4\n",
      "output_videos/scene_126_230.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_230.mp4\n",
      "Writing video to output_videos/scene_126_250.mp4\n",
      "output_videos/scene_126_230.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_230.mp4\n",
      "Writing video to output_videos/scene_126_250.mp4\n",
      "output_videos/scene_126_250.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_250.mp4\n",
      "output_videos/scene_126_250.mp4\n",
      "Processing video: /home/daniel/Dev/ms_proj/stu_dataset/output_videos/scene_126_250.mp4\n"
     ]
    }
   ],
   "source": [
    "# Quick Test\n",
    "\n",
    "from stu_video_dataset import stu_video_dataloader\n",
    "# from stu_dataset.stu_video_dataset import stu_video_dataloader\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = \"/home/daniel/Dev/ms_proj/stu_dataset/val\"\n",
    "# make output_videos directory if it does not exist\n",
    "output_videos_dir = Path(\"./output_videos/\")\n",
    "output_videos_dir.mkdir(parents=True, exist_ok=True)\n",
    "# http://127.0.0.1:8888/tree?token=b9141ba810aadad78f126e8260ed48bfe9adb7da040a8cdb\n",
    "\n",
    "for video_file, _, _ in stu_video_dataloader(dataset_dir, window_size=50, step_size=20, fps=10, separate_videos=True, output_dir=\"./output_videos/\"):\n",
    "    video_path = str(Path(video_file).absolute())\n",
    "    print(video_file)\n",
    "    print(\"Processing video:\", video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d607abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "video_dir = \"output_videos/\"\n",
    "video_files = glob.glob(os.path.join(video_dir, \"*.mp4\")) + \\\n",
    "                  glob.glob(os.path.join(video_dir, \"*.mkv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0865969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
      "\n",
      "<think>\n",
      "- Obstacles, pedestrians, or vehicles violating rules\n",
      "- Roadwork, blocked lanes, poor visibility, or hazards\n",
      "- Reflections, shadows, or false visual cues confusing perception\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "Describe the events in this video in detail.\n",
      "</answer>\n",
      "You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
      "\n",
      "<think>\n",
      "- Obstacles, pedestrians, or vehicles violating rules\n",
      "- Roadwork, blocked lanes, poor visibility, or hazards\n",
      "- Reflections, shadows, or false visual cues confusing perception\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "What is happening in this scene?\n",
      "</answer>\n",
      "You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
      "\n",
      "<think>\n",
      "- Obstacles, pedestrians, or vehicles violating rules\n",
      "- Roadwork, blocked lanes, poor visibility, or hazards\n",
      "- Reflections, shadows, or false visual cues confusing perception\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "Explain the physics observed in this video.\n",
      "</answer>\n",
      "You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
      "\n",
      "<think>\n",
      "- Obstacles, pedestrians, or vehicles violating rules\n",
      "- Roadwork, blocked lanes, poor visibility, or hazards\n",
      "- Reflections, shadows, or false visual cues confusing perception\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "Is there any anomaly in this footage?\n",
      "</answer>\n",
      "You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
      "\n",
      "<think>\n",
      "- Obstacles, pedestrians, or vehicles violating rules\n",
      "- Roadwork, blocked lanes, poor visibility, or hazards\n",
      "- Reflections, shadows, or false visual cues confusing perception\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "List the objects visible in the video.\n",
      "</answer>\n",
      "You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
      "\n",
      "<think>\n",
      "- Obstacles, pedestrians, or vehicles violating rules\n",
      "- Roadwork, blocked lanes, poor visibility, or hazards\n",
      "- Reflections, shadows, or false visual cues confusing perception\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "Is there any external anomaly in this video? Reply with exactly one word of the following:\n",
      "Classification: Anomaly — if any obstacle, obstruction, or unsafe condition is visible.\n",
      "Classification: Normal — if no anomaly or obstruction is visible.\n",
      "</answer>\n",
      "You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
      "\n",
      "<think>\n",
      "- Obstacles, pedestrians, or vehicles violating rules\n",
      "- Roadwork, blocked lanes, poor visibility, or hazards\n",
      "- Reflections, shadows, or false visual cues confusing perception\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "Describe the events in this video in detail.\n",
      "</answer>\n",
      "You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
      "\n",
      "<think>\n",
      "- Obstacles, pedestrians, or vehicles violating rules\n",
      "- Roadwork, blocked lanes, poor visibility, or hazards\n",
      "- Reflections, shadows, or false visual cues confusing perception\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "What is happening in this scene?\n",
      "</answer>\n",
      "You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
      "\n",
      "<think>\n",
      "- Obstacles, pedestrians, or vehicles violating rules\n",
      "- Roadwork, blocked lanes, poor visibility, or hazards\n",
      "- Reflections, shadows, or false visual cues confusing perception\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "Explain the physics observed in this video.\n",
      "</answer>\n",
      "You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\n",
      "\n",
      "<think>\n",
      "- Obstacles, pedestrians, or vehicles violating rules\n",
      "- Roadwork, blocked lanes, poor visibility, or hazards\n",
      "- Reflections, shadows, or false visual cues confusing perception\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "Is there any anomaly in this footage?\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "# Varied prompts for calibration\n",
    "base_prompts = [\n",
    "    \"Describe the events in this video in detail.\\n\",\n",
    "    \"What is happening in this scene?\\n\",\n",
    "    \"Explain the physics observed in this video.\\n\",\n",
    "    \"Is there any anomaly in this footage?\\n\",\n",
    "    \"List the objects visible in the video.\\n\",\n",
    "    (\n",
    "    \"Is there any external anomaly in this video? Reply with exactly one word of the following:\\n\"\n",
    "    \"Classification: Anomaly — if any obstacle, obstruction, or unsafe condition is visible.\\n\"\n",
    "    \"Classification: Normal — if no anomaly or obstruction is visible.\\n\"\n",
    "    )\n",
    "]\n",
    "\n",
    "base_text = (\n",
    "    \"You are an autonomous driving safety expert analyzing this video for EXTERNAL ANOMALIES that may impact safe AV operation.\\n\\n\"\n",
    "    \"<think>\\n\"\n",
    "    \"- Obstacles, pedestrians, or vehicles violating rules\\n\"\n",
    "    \"- Roadwork, blocked lanes, poor visibility, or hazards\\n\"\n",
    "    \"- Reflections, shadows, or false visual cues confusing perception\\n\"\n",
    "    \"</think>\\n\\n\"\n",
    "    \"<answer>\\n\"\n",
    "    )\n",
    "\n",
    "count = 0\n",
    "# Lazy imports for video handling if needed by processor\n",
    "\n",
    "while count < 10:            \n",
    "        prompt_text = base_text + base_prompts[count % len(base_prompts)] + \"</answer>\"\n",
    "        print(prompt_text)\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
