{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7347974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# import torch\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# Normalize intensities\n",
    "def normalize_intensities(intensities):\n",
    "    return np.clip(intensities / 255, 0, 1)\n",
    "\n",
    "\n",
    "# Filter points that are inside a given polygon\n",
    "def filter_points_in_polygon(image_points, polygon, corresponding_3d_points):\n",
    "    path = Path(polygon)\n",
    "    inside = path.contains_points(image_points)\n",
    "    return image_points[inside], corresponding_3d_points[inside], inside\n",
    "\n",
    "\n",
    "# Save colored point cloud as a PCD file\n",
    "def save_colored_pcd(points, colors, output_pcd_file):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    o3d.io.write_point_cloud(output_pcd_file, pcd)\n",
    "    print(f\"Saved colored PCD at: {output_pcd_file}\")\n",
    "\n",
    "\n",
    "def load_point_cloud(scan_path):\n",
    "    scan = np.fromfile(scan_path, dtype=np.float32)\n",
    "    scan = scan.reshape(\n",
    "        (-1, 4)\n",
    "    )  # The point cloud data is stored in a Nx4 format (x, y, z, intensity)\n",
    "    points = scan[:, :3]  # Extracting the (x, y, z) coordinates\n",
    "    intensities = scan[:, 3:]  # Extracting the (x, y, z) coordinates\n",
    "    return (points, intensities)\n",
    "\n",
    "\n",
    "def load_labels(label_path):\n",
    "    labels = np.fromfile(label_path, dtype=np.uint32).astype(np.int32)\n",
    "    semantic_label = labels & 0xFFFF\n",
    "    instance_label = labels >> 16\n",
    "    return semantic_label, instance_label\n",
    "\n",
    "\n",
    "def project_points_pinhole(points, camera_matrix, dist_coeffs):\n",
    "    if points.size == 0:\n",
    "        return (np.array([]), np.array([]))\n",
    "    rvec = np.zeros((3, 1))\n",
    "    tvec = np.zeros((3, 1))\n",
    "    image_points, _ = cv2.projectPoints(\n",
    "        points.reshape(-1, 1, 3), rvec, tvec, camera_matrix, dist_coeffs\n",
    "    )\n",
    "    image_points = image_points.reshape(-1, 2)\n",
    "    return image_points\n",
    "\n",
    "\n",
    "def transform_points(points, T):\n",
    "    points_hom = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    points_transformed = (T @ points_hom.T).T[:, :3]\n",
    "    return points_transformed\n",
    "\n",
    "\n",
    "def get_image_labels(\n",
    "    base_path,\n",
    "    idx,\n",
    "    image_width,\n",
    "    image_height,\n",
    "    camera_matrix,\n",
    "    dist_coeffs,\n",
    "    translation,\n",
    "    yaw,\n",
    "    pitch,\n",
    "    roll,\n",
    "):\n",
    "    label_file = base_path / f\"labels/{idx:06d}.label\"\n",
    "    point_file = base_path / f\"velodyne/{idx:06d}.bin\"\n",
    "    # \n",
    "    label_file = Path(label_file)\n",
    "    labels, _ = load_labels(label_file)\n",
    "    points, _ = load_point_cloud(point_file)\n",
    "    # \n",
    "    labels[(labels != 2) & (labels != 0)] = 1\n",
    "    # \n",
    "    # Construct the transformation matrix\n",
    "    r = R.from_euler(\"ZYX\", [yaw, pitch, roll])\n",
    "    rotation_matrix = r.as_matrix()\n",
    "    transformation_inv = np.eye(4)\n",
    "    transformation_inv[:3, :3] = rotation_matrix.T\n",
    "    transformation_inv[:3, 3] = -np.dot(rotation_matrix.T, translation)\n",
    "    # \n",
    "    # Transform points into the camera frame\n",
    "    points_transformed = transform_points(points, transformation_inv)\n",
    "    # \n",
    "    # Use only points in front of the camera (z > 0)\n",
    "    valid_indices = points_transformed[:, 2] > 0\n",
    "    points_camera_valid = points_transformed[valid_indices]\n",
    "    valid_labels = labels[valid_indices]\n",
    "    # \n",
    "    # Project to image plane\n",
    "    image_points = project_points_pinhole(\n",
    "        points_camera_valid, camera_matrix, dist_coeffs\n",
    "    )\n",
    "    # \n",
    "    # Convert projected points to integer coordinates\n",
    "    pts_int = image_points.astype(int)\n",
    "    # \n",
    "    # Filter points that lie within image bounds\n",
    "    inside_mask = (\n",
    "        (pts_int[:, 0] >= 0)\n",
    "        & (pts_int[:, 0] < image_width)\n",
    "        & (pts_int[:, 1] >= 0)\n",
    "        & (pts_int[:, 1] < image_height)\n",
    "    )\n",
    "    pts_in = pts_int[inside_mask]\n",
    "    valid_labels = valid_labels[inside_mask]\n",
    "    # \n",
    "    # return pts_in, valid_labels, image\n",
    "    return np.hstack((pts_in, valid_labels[:, None]))\n",
    "\n",
    "\n",
    "# class STUDataset(Dataset):\n",
    "class STUDataset():\n",
    "    def __init__(self, base_path, offset=0, transform=None):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.transform = transform\n",
    "        self.offset = offset\n",
    "        self.data = sorted(list(self.base_path.glob(\"*/velodyne/*.bin\")))\n",
    "        # \n",
    "        self.image_width = 1920\n",
    "        self.image_height = 1208\n",
    "        self.camera_matrix = np.array(\n",
    "            [\n",
    "                [1827.48989, 0.0, 925.91346],\n",
    "                [0.0, 1835.88358, 642.07154],\n",
    "                [0.0, 0.0, 1.0],\n",
    "            ]\n",
    "        )\n",
    "        self.dist_coeffs = np.array([-0.260735, 0.046071, 0.001173, -0.000154, 0.0])\n",
    "        self.translation = np.array([0.7658, 0.0124, -0.3925])\n",
    "        self.yaw = -1.5599\n",
    "        self.pitch = 0.0188\n",
    "        self.roll = -1.5563\n",
    "    # \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    # \n",
    "    def __getitem__(self, idx):\n",
    "        # 2 - anomaly\n",
    "        # 0 - ignore\n",
    "        # 1 - inlier\n",
    "        base_path = self.data[idx].parent.parent\n",
    "        idx = int(self.data[idx].stem)\n",
    "        image_file = str(base_path / \"port_a_cam_0\" / (f\"{idx:06d}\" + \".png\"))\n",
    "        image = Image.open(image_file)  # BGR format by default\n",
    "        # \n",
    "        # Apply optional transformation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # \n",
    "        label = get_image_labels(\n",
    "            base_path,\n",
    "            idx,\n",
    "            image.size[0],\n",
    "            image.size[1],\n",
    "            self.camera_matrix,\n",
    "            self.dist_coeffs,\n",
    "            self.translation,\n",
    "            self.yaw,\n",
    "            self.pitch,\n",
    "            self.roll,\n",
    "        )\n",
    "        # \n",
    "        return image, label, image_file\n",
    "\n",
    "    def get_predictions_targets(self, uncertainty, target):\n",
    "        coords = target.squeeze(0)\n",
    "\n",
    "        # Separate indices\n",
    "        x_indices = coords[:, 0]  # Width (columns)\n",
    "        y_indices = coords[:, 1]  # Height (rows)\n",
    "        labels_1 = coords[\n",
    "            :, 2\n",
    "        ]  # Label (0 = negative, 1 = positive, 2 = ignored)\n",
    "\n",
    "        x_indices = torch.clamp(x_indices, 0, self.image_width - 1)\n",
    "        y_indices = torch.clamp(y_indices, 0, self.image_height - 1)\n",
    "\n",
    "        # Sample pixel values\n",
    "        sampled_values = uncertainty[y_indices, x_indices]\n",
    "\n",
    "        # Separate into categories\n",
    "        uncertainty = sampled_values[labels_1 != 0]  # Pixels with label 0\n",
    "        labels = labels_1[labels_1 != 0] - 1\n",
    "        return uncertainty, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfc82f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = \"\"\"Installing collected packages: fastjsonschema, addict, rpds-py, retrying, importlib-metadata, configargparse, attrs, referencing, jsonschema-specifications, dash, jsonschema, nbformat, open3d\n",
    "Successfully installed addict-2.4.0 attrs-25.4.0 configargparse-1.7.1 dash-3.2.0 fastjsonschema-2.21.2 importlib-metadata-8.7.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 nbformat-5.10.4 open3d-0.19.0 referencing-0.37.0 retrying-1.4.2 rpds-py-0.27.1\"\"\".split(' ')\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb20e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that yields size(=10) elements from a list and slides with a window step size of step_size(=2)\n",
    "def image_from_path(path):\n",
    "    return Image.open(path)\n",
    "\n",
    "def iter_list(my_list, window_size=10, step_size=2):\n",
    "    if window_size > len(my_list):\n",
    "        yield my_list\n",
    "        return\n",
    "    \n",
    "    ret = [my_list[i] for i in range(window_size - step_size)] # get the first window_size - step_size elements\n",
    "    for i in range(window_size - step_size, len(my_list), step_size):\n",
    "        ret.extend([my_list[i + x] for x in range(step_size) if (i + x) < len(my_list)])\n",
    "        yield ret\n",
    "        ret = ret[step_size:]  # slide the window by step_size\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35dbcd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in iter_list(ds, window_size=5, step_size=2):\n",
    "#     print(chunk)\n",
    "\n",
    "ds_iter = iter_list(ds, window_size=5, step_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f22ea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addict,', 'rpds-py,', 'retrying,', 'importlib-metadata,', 'configargparse,']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ds_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fa83e",
   "metadata": {},
   "source": [
    "# STU Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "018464a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 6, 3),\n",
       " array([[[ 321,    5,    0],\n",
       "         [ 332,    6,    0],\n",
       "         [ 343,    6,    0],\n",
       "         [1884, 1207,    1],\n",
       "         [1897, 1207,    1],\n",
       "         [1909, 1207,    1]],\n",
       " \n",
       "        [[ 288,    4,    0],\n",
       "         [ 299,    5,    0],\n",
       "         [ 310,    5,    0],\n",
       "         [1885, 1206,    2],\n",
       "         [1898, 1206,    1],\n",
       "         [1911, 1206,    1]]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[[ 321,    5,    0],\n",
    "         [ 332,    6,    0],\n",
    "         [ 343,    6,    0],\n",
    "         [1884, 1207,    1],\n",
    "         [1897, 1207,    1],\n",
    "         [1909, 1207,    1]],\n",
    "\n",
    "        [[ 288,    4,    0],\n",
    "         [ 299,    5,    0],\n",
    "         [ 310,    5,    0],\n",
    "         [1885, 1206,    2],\n",
    "         [1898, 1206,    1],\n",
    "         [1911, 1206,    1]]\n",
    "]\n",
    "\n",
    "a2 = [[ 321,    5,    0],\n",
    "         [ 332,    6,    0],\n",
    "         [ 343,    6,    0],\n",
    "         [1884, 1207,    1],\n",
    "         [1897, 1207,    1],\n",
    "         [1909, 1207,    1]]\n",
    "\n",
    "a = np.array(a)\n",
    "a.shape, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52eb1349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 321    5    0]\n",
      " [ 332    6    0]\n",
      " [ 343    6    0]\n",
      " [1884 1207    1]\n",
      " [1897 1207    1]\n",
      " [1909 1207    1]]\n"
     ]
    }
   ],
   "source": [
    "a_labels = a[:, :, 2]\n",
    "# a_labels.shape, a_labels\n",
    "for i in a:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "767ea67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(a_labels == 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ds_chunk(chunk, anomaly_label=2):\n",
    "    # chunk: [(image, label, image_file_path), ...]\n",
    "    # return ([images], single_label)\n",
    "    # extract images and labels    \n",
    "    images = [item[0] for item in chunk]\n",
    "    labels = [item[1] for item in chunk]\n",
    "    # \n",
    "    # process labels\n",
    "    # labels: [[[x1, y1, label1], [x2, y2, label2], ...], ...]\n",
    "    # extract a single lable for each [x1, y1, label1], [x2, y2, label2], ...] in the labels list\n",
    "    # flaten labels on second axis\n",
    "    # \n",
    "    processed_labels = [np.any(label[:, 2] == anomaly_label) for label in labels]\n",
    "    # processed_labels = [\n",
    "    # for label in labels:\n",
    "        # processed_labels.append(np.any(label[:, 2] == anomaly_label))\n",
    "    # processed_labels = np.any(labels[:, :, 2] == anomaly_label, axis=1)\n",
    "    # \n",
    "    return images, processed_labels # images: [PIL Image], processed_labels: [np.boolean]\n",
    "\n",
    "def video_from_images(image_list, output_path, fps=10):\n",
    "    if len(image_list) == 0:\n",
    "        print(\"No images to create video.\")\n",
    "        return\n",
    "    # \n",
    "    # Get dimensions from the first image\n",
    "    first_image = image_list[0]\n",
    "    width, height = first_image.size\n",
    "    # \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can use other codecs as well\n",
    "    video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    # \n",
    "    for img in image_list:\n",
    "        # Convert PIL Image to OpenCV format\n",
    "        img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "        video_writer.write(img_cv)\n",
    "    # \n",
    "    video_writer.release()\n",
    "    print(f\"Video saved at {output_path}\")\n",
    "\n",
    "def iter_ds(ds, window_size=10, step_size=2, video_output_path=\"output_video.mp4\", fps=10):\n",
    "    if window_size > len(ds):\n",
    "        images, labels = process_ds_chunk(ds)\n",
    "        # create a video from images\n",
    "        video_from_images(images, video_output_path, fps=fps)\n",
    "        yield video_output_path, np.any(labels)\n",
    "        return\n",
    "    # \n",
    "    ret, ret_labels = process_ds_chunk([ds[i] for i in range(window_size - step_size)]) # get the first window_size - step_size frames\n",
    "    for i in range(window_size - step_size, len(ds), step_size):\n",
    "        # get the next step_size frames and labels\n",
    "        ext = [ds[i + x] for x in range(step_size) if (i + x) < len(ds)]\n",
    "        images, labels = process_ds_chunk(ext)\n",
    "        #   \n",
    "        # update ret and ret_labels\n",
    "        ret.extend(images)\n",
    "        ret_labels.extend(labels)\n",
    "        # \n",
    "        # create a video from images\n",
    "        video_from_images(ret, video_output_path, fps=fps)\n",
    "        yield video_output_path, np.any(ret_labels) \n",
    "        # \n",
    "        # shift the window\n",
    "        ret = ret[step_size:]  # slide the window by step_size\n",
    "        ret_labels = ret_labels[step_size:]\n",
    "\n",
    "        # if first yield return ret, otherwise return ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = STUDataset(\"./ms_proj/val/\")\n",
    "ds_iter = iter_ds(ds, window_size=10, step_size=2, video_output_path=\"output_video.mp4\", fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b05d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenesisRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
